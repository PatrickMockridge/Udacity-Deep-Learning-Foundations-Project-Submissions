{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 3:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]\n",
      "\n",
      "Example of Image 7:\n",
      "Image - Min Value: 12 Max Value: 254\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 3 Name: cat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\negBoTNADQGP/B1CUkEnRJdAzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f468d7b5fd0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 7\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.asarray(x/255)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    y = np.zeros(10)\n",
    "    np.put(y, x, 1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    list = []\n",
    "    for i in x:\n",
    "        list.append(encode(i))\n",
    "\n",
    "    return np.array(list)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1], image_shape[2]], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], \\\n",
    "                    x_tensor.get_shape().as_list()[3], conv_num_outputs], stddev=0.3))\n",
    "    \n",
    "    bias   = tf.Variable(tf.truncated_normal([conv_num_outputs], stddev=0.3))\n",
    "    \n",
    "    x_tensor = tf.nn.conv2d(x_tensor, weight, [1, conv_strides[0], conv_strides[1], 1], \\\n",
    "                    padding='SAME')\n",
    "    \n",
    "    x_tensor = tf.nn.bias_add(x_tensor, bias)\n",
    "    \n",
    "    x_tensor = tf.nn.softmax(x_tensor)\n",
    "    \n",
    "    x_tensor = tf.nn.max_pool(x_tensor, [1, pool_ksize[0], pool_ksize[1], 1], \\\n",
    "                              [1, pool_strides[0], pool_strides[1], 1], padding='SAME')\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs, tf.nn.tanh)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    ### PARAMETERS\n",
    "    \n",
    "    conv_ksize       = (8, 8)\n",
    "    conv_strides     = (conv_ksize[0]/2, conv_ksize[1]/2) # (4, 4)\n",
    "    conv_num_outputs = conv_ksize[0]*conv_ksize[1]        # 64\n",
    "    \n",
    "    pool_ksize       = (conv_strides[0], conv_strides[1]) # (4, 4)\n",
    "    pool_strides     = (pool_ksize[0]/2, pool_ksize[1]/2) # (2, 2)\n",
    "    \n",
    "    num_outputs      = 10\n",
    "    \n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    conv2d_maxpool_layer_1 = conv2d_maxpool(x, \\\n",
    "                                conv_num_outputs, conv_ksize, conv_strides, \\\n",
    "                                pool_ksize, pool_strides)\n",
    "    \n",
    "    conv2d_maxpool_layer_2 = conv2d_maxpool(conv2d_maxpool_layer_1, \\\n",
    "                                conv_num_outputs, conv_ksize, conv_strides, \\\n",
    "                                pool_ksize, pool_strides)\n",
    "    \n",
    "    conv2d_maxpool_layer_3 = conv2d_maxpool(conv2d_maxpool_layer_2, \\\n",
    "                                conv_num_outputs, conv_ksize, conv_strides, \\\n",
    "                                pool_ksize, pool_strides)\n",
    "    \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    \n",
    "    \n",
    "    flatten_layer = flatten(conv2d_maxpool_layer_3)\n",
    "    flatten_layer = tf.nn.dropout(flatten_layer, keep_prob)\n",
    "    \n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    \n",
    "    fully_conn_layer = fully_conn(flatten_layer, num_outputs*2)\n",
    "    fully_conn_layer = tf.nn.dropout(fully_conn_layer, keep_prob)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    output_layer = output(fully_conn_layer, num_outputs)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    \n",
    "    session.run(optimizer, feed_dict={x: feature_batch, \\\n",
    "                                      y: label_batch, \\\n",
    "                                      keep_prob: keep_probability})\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1. })\n",
    "    \n",
    "    accur = session.run(accuracy, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "    \n",
    "    print('Loss: {:.4f}  Validation Accuracy: {:.2f}%'.format(loss, accur*100), end='\\r')\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 400\n",
    "batch_size = 2048\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199, CIFAR-10 Batch 1:  oss: 2.3029  Validation Accuracy: 9.41%Loss: 2.3027  Validation Accuracy: 10.27%Loss: 2.3024  Validation Accuracy: 10.27%Loss: 2.3023  Validation Accuracy: 10.27%Loss: 2.3020  Validation Accuracy: 10.27%Loss: 2.3018  Validation Accuracy: 10.27%Loss: 2.3015  Validation Accuracy: 15.84%Loss: 2.3012  Validation Accuracy: 17.08%Loss: 2.3008  Validation Accuracy: 15.35%Loss: 2.3004  Validation Accuracy: 15.10%Loss: 2.2999  Validation Accuracy: 16.96%Loss: 2.2994  Validation Accuracy: 17.08%Loss: 2.2988  Validation Accuracy: 17.33%Loss: 2.2980  Validation Accuracy: 17.70%Loss: 2.2970  Validation Accuracy: 17.95%Loss: 2.2958  Validation Accuracy: 17.95%Loss: 2.2943  Validation Accuracy: 15.84%Loss: 2.2926  Validation Accuracy: 16.46%Loss: 2.2907  Validation Accuracy: 15.59%Loss: 2.2887  Validation Accuracy: 15.97%Loss: 2.2864  Validation Accuracy: 15.97%Loss: 2.2839  Validation Accuracy: 15.84%Loss: 2.2812  Validation Accuracy: 15.84%Loss: 2.2783  Validation Accuracy: 15.97%Loss: 2.2750  Validation Accuracy: 15.97%Loss: 2.2714  Validation Accuracy: 15.84%Loss: 2.2657  Validation Accuracy: 15.84%Loss: 2.2597  Validation Accuracy: 15.84%Loss: 2.2534  Validation Accuracy: 15.97%Loss: 2.2468  Validation Accuracy: 16.46%Loss: 2.2397  Validation Accuracy: 16.58%Loss: 2.2324  Validation Accuracy: 16.34%Loss: 2.2235  Validation Accuracy: 16.46%Loss: 2.2154  Validation Accuracy: 16.21%Loss: 2.2080  Validation Accuracy: 16.34%Loss: 2.1996  Validation Accuracy: 16.21%Loss: 2.1910  Validation Accuracy: 16.09%Loss: 2.1821  Validation Accuracy: 16.21%Loss: 2.1740  Validation Accuracy: 16.21%Loss: 2.1662  Validation Accuracy: 16.21%Loss: 2.1566  Validation Accuracy: 16.21%Loss: 2.1450  Validation Accuracy: 16.21%Loss: 2.1350  Validation Accuracy: 16.46%Loss: 2.1252  Validation Accuracy: 16.83%Loss: 2.1159  Validation Accuracy: 16.58%Loss: 2.1061  Validation Accuracy: 16.96%Loss: 2.0973  Validation Accuracy: 16.96%Loss: 2.0898  Validation Accuracy: 16.96%Loss: 2.0810  Validation Accuracy: 17.33%Loss: 2.0728  Validation Accuracy: 18.07%Loss: 2.0679  Validation Accuracy: 17.45%Loss: 2.0604  Validation Accuracy: 17.82%Loss: 2.0485  Validation Accuracy: 19.18%Loss: 2.0355  Validation Accuracy: 19.31%Loss: 2.0245  Validation Accuracy: 19.93%Loss: 2.0146  Validation Accuracy: 19.93%Loss: 2.0031  Validation Accuracy: 19.93%Loss: 1.9944  Validation Accuracy: 20.30%Loss: 1.9864  Validation Accuracy: 19.93%Loss: 1.9774  Validation Accuracy: 19.93%Loss: 1.9690  Validation Accuracy: 20.17%Loss: 1.9606  Validation Accuracy: 20.17%Loss: 1.9532  Validation Accuracy: 20.30%Loss: 1.9470  Validation Accuracy: 19.68%Loss: 1.9412  Validation Accuracy: 20.30%Loss: 1.9358  Validation Accuracy: 20.79%Loss: 1.9293  Validation Accuracy: 21.16%Loss: 1.9245  Validation Accuracy: 19.80%Loss: 1.9204  Validation Accuracy: 19.55%Loss: 1.9153  Validation Accuracy: 19.68%Loss: 1.9116  Validation Accuracy: 19.55%Loss: 1.9080  Validation Accuracy: 19.68%Loss: 1.9040  Validation Accuracy: 20.05%Loss: 1.9001  Validation Accuracy: 20.54%Loss: 1.8967  Validation Accuracy: 21.04%Loss: 1.8935  Validation Accuracy: 21.04%Loss: 1.8906  Validation Accuracy: 21.16%Loss: 1.8872  Validation Accuracy: 21.16%Loss: 1.8842  Validation Accuracy: 21.16%Loss: 1.8817  Validation Accuracy: 21.53%Loss: 1.8787  Validation Accuracy: 21.66%Loss: 1.8759  Validation Accuracy: 21.66%Loss: 1.8735  Validation Accuracy: 21.53%Loss: 1.8712  Validation Accuracy: 21.41%Loss: 1.8682  Validation Accuracy: 21.78%Loss: 1.8660  Validation Accuracy: 21.53%Loss: 1.8638  Validation Accuracy: 21.41%Loss: 1.8617  Validation Accuracy: 21.29%Loss: 1.8594  Validation Accuracy: 21.53%Loss: 1.8600  Validation Accuracy: 21.91%Loss: 1.8546  Validation Accuracy: 21.41%Loss: 1.8528  Validation Accuracy: 21.53%Loss: 1.8503  Validation Accuracy: 21.91%Loss: 1.8487  Validation Accuracy: 21.53%Loss: 1.8459  Validation Accuracy: 21.41%Loss: 1.8431  Validation Accuracy: 21.29%Loss: 1.8411  Validation Accuracy: 21.41%Loss: 1.8393  Validation Accuracy: 21.66%Loss: 1.8378  Validation Accuracy: 21.91%Loss: 1.8347  Validation Accuracy: 21.53%Loss: 1.8333  Validation Accuracy: 21.78%Loss: 1.8314  Validation Accuracy: 21.66%Loss: 1.8294  Validation Accuracy: 21.41%Loss: 1.8271  Validation Accuracy: 21.29%Loss: 1.8251  Validation Accuracy: 21.29%Loss: 1.8231  Validation Accuracy: 21.41%Loss: 1.8212  Validation Accuracy: 21.53%Loss: 1.8202  Validation Accuracy: 21.66%Loss: 1.8193  Validation Accuracy: 21.41%Loss: 1.8187  Validation Accuracy: 21.66%Loss: 1.8151  Validation Accuracy: 21.53%Loss: 1.8136  Validation Accuracy: 21.78%Loss: 1.8114  Validation Accuracy: 21.16%Loss: 1.8099  Validation Accuracy: 21.53%Loss: 1.8086  Validation Accuracy: 21.66%Loss: 1.8073  Validation Accuracy: 21.91%Loss: 1.8066  Validation Accuracy: 22.28%Loss: 1.8051  Validation Accuracy: 22.03%Loss: 1.8033  Validation Accuracy: 22.15%Loss: 1.8027  Validation Accuracy: 22.15%Loss: 1.8020  Validation Accuracy: 22.28%Loss: 1.8001  Validation Accuracy: 22.65%Loss: 1.7983  Validation Accuracy: 21.91%Loss: 1.7970  Validation Accuracy: 22.28%Loss: 1.7957  Validation Accuracy: 22.40%Loss: 1.7947  Validation Accuracy: 22.28%Loss: 1.7945  Validation Accuracy: 23.27%Loss: 1.7923  Validation Accuracy: 24.26%Loss: 1.7906  Validation Accuracy: 23.39%Loss: 1.7890  Validation Accuracy: 23.64%Loss: 1.7868  Validation Accuracy: 24.13%Loss: 1.7849  Validation Accuracy: 24.01%Loss: 1.7829  Validation Accuracy: 24.38%Loss: 1.7814  Validation Accuracy: 24.13%Loss: 1.7783  Validation Accuracy: 23.89%Loss: 1.7752  Validation Accuracy: 24.75%Loss: 1.7720  Validation Accuracy: 23.89%Loss: 1.7693  Validation Accuracy: 24.26%Loss: 1.7669  Validation Accuracy: 24.38%Loss: 1.7647  Validation Accuracy: 24.63%Loss: 1.7625  Validation Accuracy: 24.75%Loss: 1.7594  Validation Accuracy: 24.75%Loss: 1.7572  Validation Accuracy: 24.88%Loss: 1.7543  Validation Accuracy: 25.50%Loss: 1.7517  Validation Accuracy: 26.11%Loss: 1.7494  Validation Accuracy: 26.11%Loss: 1.7470  Validation Accuracy: 26.11%Loss: 1.7442  Validation Accuracy: 26.36%Loss: 1.7424  Validation Accuracy: 27.23%Loss: 1.7402  Validation Accuracy: 27.60%Loss: 1.7373  Validation Accuracy: 27.60%Loss: 1.7344  Validation Accuracy: 28.47%Loss: 1.7326  Validation Accuracy: 29.08%Loss: 1.7309  Validation Accuracy: 29.95%Loss: 1.7287  Validation Accuracy: 29.95%Loss: 1.7252  Validation Accuracy: 29.70%Loss: 1.7216  Validation Accuracy: 30.20%Loss: 1.7187  Validation Accuracy: 30.94%Loss: 1.7161  Validation Accuracy: 31.56%Loss: 1.7142  Validation Accuracy: 30.82%Loss: 1.7118  Validation Accuracy: 30.94%Loss: 1.7110  Validation Accuracy: 32.05%Loss: 1.7067  Validation Accuracy: 30.94%Loss: 1.7040  Validation Accuracy: 30.94%Loss: 1.7012  Validation Accuracy: 31.31%Loss: 1.6982  Validation Accuracy: 31.19%Loss: 1.6956  Validation Accuracy: 31.81%Loss: 1.6938  Validation Accuracy: 32.30%Loss: 1.6929  Validation Accuracy: 32.18%Loss: 1.6906  Validation Accuracy: 31.93%Loss: 1.6860  Validation Accuracy: 32.05%Loss: 1.6829  Validation Accuracy: 31.31%Loss: 1.6803  Validation Accuracy: 31.56%Loss: 1.6785  Validation Accuracy: 31.19%Loss: 1.6769  Validation Accuracy: 31.44%Loss: 1.6741  Validation Accuracy: 31.31%Loss: 1.6715  Validation Accuracy: 31.68%Loss: 1.6685  Validation Accuracy: 32.43%Loss: 1.6651  Validation Accuracy: 32.55%Loss: 1.6629  Validation Accuracy: 32.80%Loss: 1.6611  Validation Accuracy: 32.67%Loss: 1.6580  Validation Accuracy: 33.04%Loss: 1.6555  Validation Accuracy: 33.04%Loss: 1.6534  Validation Accuracy: 32.55%Loss: 1.6505  Validation Accuracy: 33.17%Loss: 1.6477  Validation Accuracy: 33.29%Loss: 1.6450  Validation Accuracy: 33.04%Loss: 1.6426  Validation Accuracy: 33.66%Loss: 1.6402  Validation Accuracy: 32.92%Loss: 1.6379  Validation Accuracy: 33.54%Loss: 1.6360  Validation Accuracy: 33.91%Loss: 1.6336  Validation Accuracy: 34.03%Loss: 1.6305  Validation Accuracy: 34.41%Loss: 1.6284  Validation Accuracy: 34.16%Loss: 1.6264  Validation Accuracy: 33.79%Loss: 1.6257  Validation Accuracy: 33.66%Loss: 1.6241  Validation Accuracy: 33.17%Loss: 1.6185  Validation Accuracy: 33.42%Loss: 1.6134  Validation Accuracy: 35.02%\r",
      "Epoch 200, CIFAR-10 Batch 1:  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399, CIFAR-10 Batch 1:  acy: 34.65%Loss: 1.6081  Validation Accuracy: 34.78%Loss: 1.6046  Validation Accuracy: 34.65%Loss: 1.6005  Validation Accuracy: 35.64%Loss: 1.5973  Validation Accuracy: 35.40%Loss: 1.5948  Validation Accuracy: 35.64%Loss: 1.5928  Validation Accuracy: 35.89%Loss: 1.5893  Validation Accuracy: 36.01%Loss: 1.5862  Validation Accuracy: 36.39%Loss: 1.5837  Validation Accuracy: 36.26%Loss: 1.5807  Validation Accuracy: 36.14%Loss: 1.5778  Validation Accuracy: 35.89%Loss: 1.5756  Validation Accuracy: 35.77%Loss: 1.5728  Validation Accuracy: 35.77%Loss: 1.5708  Validation Accuracy: 35.77%Loss: 1.5704  Validation Accuracy: 35.52%Loss: 1.5678  Validation Accuracy: 36.01%Loss: 1.5655  Validation Accuracy: 35.89%Loss: 1.5613  Validation Accuracy: 36.14%Loss: 1.5561  Validation Accuracy: 36.26%Loss: 1.5533  Validation Accuracy: 36.39%Loss: 1.5511  Validation Accuracy: 37.00%Loss: 1.5511  Validation Accuracy: 36.51%Loss: 1.5501  Validation Accuracy: 36.14%Loss: 1.5487  Validation Accuracy: 36.01%Loss: 1.5433  Validation Accuracy: 36.76%Loss: 1.5369  Validation Accuracy: 36.51%Loss: 1.5333  Validation Accuracy: 38.00%Loss: 1.5307  Validation Accuracy: 37.50%Loss: 1.5324  Validation Accuracy: 37.50%Loss: 1.5284  Validation Accuracy: 38.24%Loss: 1.5248  Validation Accuracy: 38.24%Loss: 1.5186  Validation Accuracy: 38.99%Loss: 1.5156  Validation Accuracy: 38.99%Loss: 1.5133  Validation Accuracy: 38.37%Loss: 1.5111  Validation Accuracy: 39.36%Loss: 1.5072  Validation Accuracy: 38.61%Loss: 1.5037  Validation Accuracy: 39.11%Loss: 1.5002  Validation Accuracy: 39.11%Loss: 1.4978  Validation Accuracy: 39.36%Loss: 1.4962  Validation Accuracy: 38.99%Loss: 1.4939  Validation Accuracy: 39.48%Loss: 1.4900  Validation Accuracy: 40.10%Loss: 1.4857  Validation Accuracy: 39.73%Loss: 1.4828  Validation Accuracy: 40.84%Loss: 1.4803  Validation Accuracy: 41.09%Loss: 1.4779  Validation Accuracy: 40.72%Loss: 1.4738  Validation Accuracy: 41.21%Loss: 1.4713  Validation Accuracy: 41.46%Loss: 1.4674  Validation Accuracy: 40.59%Loss: 1.4645  Validation Accuracy: 41.21%Loss: 1.4612  Validation Accuracy: 41.34%Loss: 1.4586  Validation Accuracy: 41.34%Loss: 1.4560  Validation Accuracy: 41.58%Loss: 1.4524  Validation Accuracy: 41.58%Loss: 1.4496  Validation Accuracy: 41.58%Loss: 1.4471  Validation Accuracy: 41.21%Loss: 1.4453  Validation Accuracy: 41.46%Loss: 1.4416  Validation Accuracy: 40.97%Loss: 1.4406  Validation Accuracy: 40.22%Loss: 1.4366  Validation Accuracy: 41.21%Loss: 1.4322  Validation Accuracy: 41.96%Loss: 1.4281  Validation Accuracy: 42.82%Loss: 1.4257  Validation Accuracy: 43.07%Loss: 1.4245  Validation Accuracy: 42.95%Loss: 1.4220  Validation Accuracy: 43.44%Loss: 1.4204  Validation Accuracy: 43.81%Loss: 1.4149  Validation Accuracy: 44.31%Loss: 1.4100  Validation Accuracy: 43.94%Loss: 1.4092  Validation Accuracy: 43.19%Loss: 1.4100  Validation Accuracy: 43.19%Loss: 1.4120  Validation Accuracy: 42.33%Loss: 1.4049  Validation Accuracy: 43.07%Loss: 1.3981  Validation Accuracy: 43.19%Loss: 1.3937  Validation Accuracy: 44.43%Loss: 1.3954  Validation Accuracy: 44.06%Loss: 1.3908  Validation Accuracy: 45.05%Loss: 1.3861  Validation Accuracy: 44.68%Loss: 1.3828  Validation Accuracy: 44.43%Loss: 1.3829  Validation Accuracy: 44.31%Loss: 1.3816  Validation Accuracy: 43.81%Loss: 1.3790  Validation Accuracy: 43.94%Loss: 1.3737  Validation Accuracy: 45.30%Loss: 1.3736  Validation Accuracy: 45.54%Loss: 1.3730  Validation Accuracy: 44.80%Loss: 1.3665  Validation Accuracy: 45.67%Loss: 1.3637  Validation Accuracy: 45.79%Loss: 1.3638  Validation Accuracy: 45.79%Loss: 1.3641  Validation Accuracy: 44.18%Loss: 1.3561  Validation Accuracy: 46.91%Loss: 1.3547  Validation Accuracy: 46.66%Loss: 1.3536  Validation Accuracy: 46.16%Loss: 1.3493  Validation Accuracy: 47.03%Loss: 1.3462  Validation Accuracy: 47.40%Loss: 1.3451  Validation Accuracy: 46.04%Loss: 1.3421  Validation Accuracy: 47.03%Loss: 1.3392  Validation Accuracy: 47.15%Loss: 1.3358  Validation Accuracy: 47.52%Loss: 1.3341  Validation Accuracy: 47.77%Loss: 1.3310  Validation Accuracy: 47.65%Loss: 1.3279  Validation Accuracy: 49.01%Loss: 1.3247  Validation Accuracy: 48.64%Loss: 1.3218  Validation Accuracy: 48.76%Loss: 1.3207  Validation Accuracy: 48.76%Loss: 1.3194  Validation Accuracy: 48.27%Loss: 1.3193  Validation Accuracy: 47.15%Loss: 1.3168  Validation Accuracy: 48.27%Loss: 1.3113  Validation Accuracy: 48.89%Loss: 1.3070  Validation Accuracy: 49.88%Loss: 1.3054  Validation Accuracy: 49.38%Loss: 1.3070  Validation Accuracy: 48.51%Loss: 1.3072  Validation Accuracy: 47.15%Loss: 1.3027  Validation Accuracy: 48.76%Loss: 1.2975  Validation Accuracy: 48.64%Loss: 1.2938  Validation Accuracy: 51.36%Loss: 1.2931  Validation Accuracy: 50.00%Loss: 1.2933  Validation Accuracy: 50.50%Loss: 1.2952  Validation Accuracy: 49.26%Loss: 1.2877  Validation Accuracy: 49.38%Loss: 1.2861  Validation Accuracy: 49.63%Loss: 1.2821  Validation Accuracy: 49.75%Loss: 1.2824  Validation Accuracy: 50.00%Loss: 1.2862  Validation Accuracy: 48.14%Loss: 1.2898  Validation Accuracy: 47.40%Loss: 1.2786  Validation Accuracy: 49.38%Loss: 1.2727  Validation Accuracy: 50.00%Loss: 1.2832  Validation Accuracy: 50.62%Loss: 1.2777  Validation Accuracy: 50.50%Loss: 1.2685  Validation Accuracy: 50.50%Loss: 1.2670  Validation Accuracy: 50.00%Loss: 1.2653  Validation Accuracy: 50.25%Loss: 1.2613  Validation Accuracy: 51.98%Loss: 1.2594  Validation Accuracy: 51.24%Loss: 1.2592  Validation Accuracy: 50.12%Loss: 1.2565  Validation Accuracy: 50.99%Loss: 1.2546  Validation Accuracy: 50.74%Loss: 1.2526  Validation Accuracy: 50.62%Loss: 1.2499  Validation Accuracy: 50.62%Loss: 1.2477  Validation Accuracy: 51.24%Loss: 1.2469  Validation Accuracy: 51.24%Loss: 1.2447  Validation Accuracy: 51.36%Loss: 1.2425  Validation Accuracy: 51.73%Loss: 1.2420  Validation Accuracy: 51.11%Loss: 1.2391  Validation Accuracy: 51.61%Loss: 1.2377  Validation Accuracy: 51.36%Loss: 1.2372  Validation Accuracy: 52.72%Loss: 1.2346  Validation Accuracy: 51.49%Loss: 1.2338  Validation Accuracy: 51.73%Loss: 1.2320  Validation Accuracy: 51.61%Loss: 1.2304  Validation Accuracy: 51.73%Loss: 1.2286  Validation Accuracy: 51.49%Loss: 1.2267  Validation Accuracy: 51.61%Loss: 1.2249  Validation Accuracy: 52.72%Loss: 1.2230  Validation Accuracy: 52.48%Loss: 1.2211  Validation Accuracy: 51.98%Loss: 1.2196  Validation Accuracy: 51.86%Loss: 1.2197  Validation Accuracy: 51.98%Loss: 1.2173  Validation Accuracy: 52.35%Loss: 1.2161  Validation Accuracy: 52.48%Loss: 1.2136  Validation Accuracy: 53.47%Loss: 1.2125  Validation Accuracy: 51.73%Loss: 1.2128  Validation Accuracy: 51.86%Loss: 1.2116  Validation Accuracy: 52.23%Loss: 1.2078  Validation Accuracy: 52.60%Loss: 1.2055  Validation Accuracy: 53.59%Loss: 1.2051  Validation Accuracy: 53.22%Loss: 1.2039  Validation Accuracy: 53.96%Loss: 1.2022  Validation Accuracy: 53.22%Loss: 1.1995  Validation Accuracy: 52.72%Loss: 1.1991  Validation Accuracy: 53.59%Loss: 1.1970  Validation Accuracy: 53.47%Loss: 1.1948  Validation Accuracy: 53.47%Loss: 1.1954  Validation Accuracy: 53.84%Loss: 1.1927  Validation Accuracy: 54.21%Loss: 1.1911  Validation Accuracy: 52.72%Loss: 1.1898  Validation Accuracy: 53.59%Loss: 1.1878  Validation Accuracy: 53.47%Loss: 1.1884  Validation Accuracy: 53.09%Loss: 1.1861  Validation Accuracy: 52.85%Loss: 1.1840  Validation Accuracy: 54.21%Loss: 1.1833  Validation Accuracy: 53.47%Loss: 1.1839  Validation Accuracy: 53.22%Loss: 1.1920  Validation Accuracy: 53.59%Loss: 1.1897  Validation Accuracy: 53.47%Loss: 1.1859  Validation Accuracy: 53.34%Loss: 1.1781  Validation Accuracy: 54.58%Loss: 1.1750  Validation Accuracy: 54.46%Loss: 1.1814  Validation Accuracy: 52.85%Loss: 1.1800  Validation Accuracy: 53.09%Loss: 1.1727  Validation Accuracy: 54.08%Loss: 1.1712  Validation Accuracy: 54.46%Loss: 1.1735  Validation Accuracy: 53.59%Loss: 1.1680  Validation Accuracy: 53.84%Loss: 1.1658  Validation Accuracy: 54.83%Loss: 1.1667  Validation Accuracy: 54.08%Loss: 1.1649  Validation Accuracy: 53.22%Loss: 1.1605  Validation Accuracy: 54.33%Loss: 1.1591  Validation Accuracy: 53.84%Loss: 1.1586  Validation Accuracy: 54.08%Loss: 1.1567  Validation Accuracy: 54.70%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, CIFAR-10 Batch 1:  Loss: 1.1565  Validation Accuracy: 55.20%\r"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 2.3021  Validation Accuracy: 11.51%Loss: 2.3026  Validation Accuracy: 9.78%Loss: 2.3027  Validation Accuracy: 10.40%Loss: 2.3026  Validation Accuracy: 10.02%Loss: 2.3024  Validation Accuracy: 10.27%Loss: 2.3020  Validation Accuracy: 13.86%Loss: 2.3021  Validation Accuracy: 15.47%Loss: 2.3024  Validation Accuracy: 9.28%Loss: 2.3015  Validation Accuracy: 16.96%Loss: 2.3012  Validation Accuracy: 17.45%Loss: 2.3006  Validation Accuracy: 14.98%Loss: 2.3003  Validation Accuracy: 15.10%Loss: 2.3002  Validation Accuracy: 17.57%Loss: 2.2987  Validation Accuracy: 17.33%Loss: 2.2974  Validation Accuracy: 20.92%Loss: 2.2963  Validation Accuracy: 18.81%Loss: 2.2946  Validation Accuracy: 18.32%Loss: 2.2940  Validation Accuracy: 17.33%Loss: 2.2899  Validation Accuracy: 19.68%Loss: 2.2875  Validation Accuracy: 19.55%Loss: 2.2844  Validation Accuracy: 18.94%Loss: 2.2801  Validation Accuracy: 19.31%Loss: 2.2767  Validation Accuracy: 18.19%Loss: 2.2685  Validation Accuracy: 20.42%Loss: 2.2631  Validation Accuracy: 19.68%Loss: 2.2583  Validation Accuracy: 20.30%Loss: 2.2474  Validation Accuracy: 19.93%Loss: 2.2424  Validation Accuracy: 18.32%Loss: 2.2290  Validation Accuracy: 20.30%Loss: 2.2212  Validation Accuracy: 19.80%Loss: 2.2142  Validation Accuracy: 20.17%Loss: 2.1989  Validation Accuracy: 20.17%Loss: 2.1903  Validation Accuracy: 18.32%Loss: 2.1729  Validation Accuracy: 20.67%Loss: 2.1683  Validation Accuracy: 20.54%Loss: 2.1605  Validation Accuracy: 19.80%Loss: 2.1422  Validation Accuracy: 20.30%Loss: 2.1308  Validation Accuracy: 18.44%Loss: 2.1098  Validation Accuracy: 20.67%Loss: 2.1134  Validation Accuracy: 20.42%Loss: 2.1028  Validation Accuracy: 20.05%Loss: 2.0866  Validation Accuracy: 20.92%Loss: 2.0667  Validation Accuracy: 18.81%Loss: 2.0451  Validation Accuracy: 20.42%Loss: 2.0566  Validation Accuracy: 20.05%Loss: 2.0491  Validation Accuracy: 19.93%Loss: 2.0361  Validation Accuracy: 20.79%Loss: 2.0099  Validation Accuracy: 18.94%Loss: 1.9943  Validation Accuracy: 20.92%Loss: 2.0142  Validation Accuracy: 20.79%Loss: 2.0056  Validation Accuracy: 19.55%Loss: 1.9991  Validation Accuracy: 21.29%Loss: 1.9683  Validation Accuracy: 18.69%Loss: 1.9605  Validation Accuracy: 21.41%Loss: 1.9812  Validation Accuracy: 20.42%Loss: 1.9775  Validation Accuracy: 20.42%Loss: 1.9725  Validation Accuracy: 21.41%Loss: 1.9364  Validation Accuracy: 19.43%Loss: 1.9387  Validation Accuracy: 21.91%Loss: 1.9622  Validation Accuracy: 19.93%Loss: 1.9625  Validation Accuracy: 20.92%Loss: 1.9543  Validation Accuracy: 21.78%Loss: 1.9168  Validation Accuracy: 19.55%Loss: 1.9247  Validation Accuracy: 21.66%Loss: 1.9499  Validation Accuracy: 20.54%Loss: 1.9503  Validation Accuracy: 21.53%Loss: 1.9433  Validation Accuracy: 22.03%Loss: 1.9027  Validation Accuracy: 21.16%Loss: 1.9194  Validation Accuracy: 22.15%Loss: 1.9429  Validation Accuracy: 21.29%Loss: 1.9351  Validation Accuracy: 22.15%Loss: 1.9338  Validation Accuracy: 22.90%Loss: 1.8907  Validation Accuracy: 21.29%Loss: 1.9131  Validation Accuracy: 22.40%Loss: 1.9394  Validation Accuracy: 21.91%Loss: 1.9280  Validation Accuracy: 22.03%Loss: 1.9294  Validation Accuracy: 21.41%Loss: 1.8788  Validation Accuracy: 22.15%Loss: 1.9037  Validation Accuracy: 23.64%Loss: 1.9276  Validation Accuracy: 22.03%Loss: 1.9193  Validation Accuracy: 22.90%Loss: 1.9247  Validation Accuracy: 21.29%Loss: 1.8692  Validation Accuracy: 22.28%Loss: 1.8963  Validation Accuracy: 23.27%Loss: 1.9142  Validation Accuracy: 22.65%Loss: 1.9105  Validation Accuracy: 23.02%Loss: 1.9167  Validation Accuracy: 21.41%Loss: 1.8628  Validation Accuracy: 22.03%Loss: 1.8919  Validation Accuracy: 24.75%Loss: 1.9068  Validation Accuracy: 22.90%Loss: 1.9025  Validation Accuracy: 23.27%Loss: 1.9085  Validation Accuracy: 22.15%Loss: 1.8570  Validation Accuracy: 22.28%Loss: 1.8894  Validation Accuracy: 24.75%Loss: 1.9006  Validation Accuracy: 23.14%Loss: 1.8950  Validation Accuracy: 23.39%Loss: 1.9017  Validation Accuracy: 21.66%Loss: 1.8502  Validation Accuracy: 22.52%Loss: 1.8854  Validation Accuracy: 24.63%Loss: 1.8923  Validation Accuracy: 22.77%Loss: 1.8881  Validation Accuracy: 22.90%Loss: 1.8954  Validation Accuracy: 21.41%Loss: 1.8450  Validation Accuracy: 22.40%Loss: 1.8820  Validation Accuracy: 23.76%Loss: 1.8874  Validation Accuracy: 21.16%Loss: 1.8822  Validation Accuracy: 22.90%Loss: 1.8901  Validation Accuracy: 22.40%Loss: 1.8399  Validation Accuracy: 22.40%Loss: 1.8760  Validation Accuracy: 23.14%Loss: 1.8794  Validation Accuracy: 20.54%Loss: 1.8762  Validation Accuracy: 24.38%Loss: 1.8840  Validation Accuracy: 22.40%Loss: 1.8319  Validation Accuracy: 27.23%Loss: 1.8711  Validation Accuracy: 22.90%Loss: 1.8714  Validation Accuracy: 21.04%Loss: 1.8700  Validation Accuracy: 24.13%Loss: 1.8785  Validation Accuracy: 22.65%Loss: 1.8266  Validation Accuracy: 27.23%Loss: 1.8665  Validation Accuracy: 24.63%Loss: 1.8640  Validation Accuracy: 21.53%Loss: 1.8629  Validation Accuracy: 24.26%Loss: 1.8717  Validation Accuracy: 23.39%Loss: 1.8221  Validation Accuracy: 27.60%Loss: 1.8601  Validation Accuracy: 24.26%Loss: 1.8591  Validation Accuracy: 21.29%Loss: 1.8563  Validation Accuracy: 24.38%Loss: 1.8665  Validation Accuracy: 23.39%Loss: 1.8178  Validation Accuracy: 28.34%Loss: 1.8551  Validation Accuracy: 25.00%Loss: 1.8536  Validation Accuracy: 21.29%Loss: 1.8481  Validation Accuracy: 24.75%Loss: 1.8606  Validation Accuracy: 23.27%Loss: 1.8115  Validation Accuracy: 27.10%Loss: 1.8493  Validation Accuracy: 24.75%Loss: 1.8465  Validation Accuracy: 22.65%Loss: 1.8401  Validation Accuracy: 25.62%Loss: 1.8560  Validation Accuracy: 23.89%Loss: 1.8047  Validation Accuracy: 28.09%Loss: 1.8435  Validation Accuracy: 25.50%Loss: 1.8398  Validation Accuracy: 23.39%Loss: 1.8321  Validation Accuracy: 25.87%Loss: 1.8486  Validation Accuracy: 24.01%Loss: 1.8002  Validation Accuracy: 28.84%Loss: 1.8379  Validation Accuracy: 26.11%Loss: 1.8332  Validation Accuracy: 23.14%Loss: 1.8239  Validation Accuracy: 26.86%Loss: 1.8419  Validation Accuracy: 24.63%Loss: 1.7940  Validation Accuracy: 28.96%Loss: 1.8287  Validation Accuracy: 25.50%Loss: 1.8246  Validation Accuracy: 23.39%Loss: 1.8173  Validation Accuracy: 27.10%Loss: 1.8346  Validation Accuracy: 25.87%Loss: 1.7883  Validation Accuracy: 29.33%Loss: 1.8188  Validation Accuracy: 27.10%Loss: 1.8173  Validation Accuracy: 24.26%Loss: 1.8097  Validation Accuracy: 27.10%Loss: 1.8291  Validation Accuracy: 25.62%Loss: 1.7821  Validation Accuracy: 29.83%Loss: 1.8088  Validation Accuracy: 27.60%Loss: 1.8103  Validation Accuracy: 24.88%Loss: 1.8019  Validation Accuracy: 27.72%Loss: 1.8212  Validation Accuracy: 25.87%Loss: 1.7767  Validation Accuracy: 30.45%Loss: 1.8009  Validation Accuracy: 28.59%Loss: 1.8023  Validation Accuracy: 25.25%Loss: 1.7932  Validation Accuracy: 27.72%Loss: 1.8138  Validation Accuracy: 26.98%Loss: 1.7687  Validation Accuracy: 30.07%Loss: 1.7896  Validation Accuracy: 28.84%Loss: 1.7934  Validation Accuracy: 25.00%Loss: 1.7838  Validation Accuracy: 27.72%Loss: 1.8062  Validation Accuracy: 27.48%Loss: 1.7603  Validation Accuracy: 30.32%Loss: 1.7782  Validation Accuracy: 28.47%Loss: 1.7841  Validation Accuracy: 25.74%Loss: 1.7727  Validation Accuracy: 27.72%Loss: 1.7975  Validation Accuracy: 28.47%Loss: 1.7515  Validation Accuracy: 29.95%Loss: 1.7656  Validation Accuracy: 29.46%Loss: 1.7748  Validation Accuracy: 26.73%Loss: 1.7620  Validation Accuracy: 28.34%Loss: 1.7873  Validation Accuracy: 28.09%Loss: 1.7432  Validation Accuracy: 31.06%Loss: 1.7508  Validation Accuracy: 29.95%Loss: 1.7643  Validation Accuracy: 26.11%Loss: 1.7525  Validation Accuracy: 28.59%Loss: 1.7851  Validation Accuracy: 27.97%Loss: 1.7315  Validation Accuracy: 30.94%Loss: 1.7394  Validation Accuracy: 30.20%Loss: 1.7518  Validation Accuracy: 28.34%Loss: 1.7406  Validation Accuracy: 30.32%Loss: 1.7674  Validation Accuracy: 29.08%Loss: 1.7230  Validation Accuracy: 30.57%Loss: 1.7230  Validation Accuracy: 31.31%Loss: 1.7408  Validation Accuracy: 28.09%Loss: 1.7285  Validation Accuracy: 31.06%Loss: 1.7586  Validation Accuracy: 30.45%Loss: 1.7124  Validation Accuracy: 30.45%Loss: 1.7104  Validation Accuracy: 31.93%\r",
      "Epoch 40, CIFAR-10 Batch 5:  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, CIFAR-10 Batch 4:  racy: 28.22%Loss: 1.7150  Validation Accuracy: 31.56%Loss: 1.7443  Validation Accuracy: 30.32%Loss: 1.7036  Validation Accuracy: 30.82%Loss: 1.6984  Validation Accuracy: 33.54%Loss: 1.7135  Validation Accuracy: 28.84%Loss: 1.7004  Validation Accuracy: 31.81%Loss: 1.7327  Validation Accuracy: 30.20%Loss: 1.6927  Validation Accuracy: 31.93%Loss: 1.6816  Validation Accuracy: 33.79%Loss: 1.7011  Validation Accuracy: 29.08%Loss: 1.6881  Validation Accuracy: 33.04%Loss: 1.7217  Validation Accuracy: 31.31%Loss: 1.6852  Validation Accuracy: 31.81%Loss: 1.6712  Validation Accuracy: 33.91%Loss: 1.6907  Validation Accuracy: 30.45%Loss: 1.6746  Validation Accuracy: 33.54%Loss: 1.7098  Validation Accuracy: 31.56%Loss: 1.6735  Validation Accuracy: 33.17%Loss: 1.6571  Validation Accuracy: 33.42%Loss: 1.6788  Validation Accuracy: 30.94%Loss: 1.6626  Validation Accuracy: 34.90%Loss: 1.7001  Validation Accuracy: 32.05%Loss: 1.6632  Validation Accuracy: 33.17%Loss: 1.6445  Validation Accuracy: 34.78%Loss: 1.6652  Validation Accuracy: 30.82%Loss: 1.6511  Validation Accuracy: 34.28%Loss: 1.6886  Validation Accuracy: 32.18%Loss: 1.6546  Validation Accuracy: 33.54%Loss: 1.6360  Validation Accuracy: 35.15%Loss: 1.6537  Validation Accuracy: 30.69%Loss: 1.6416  Validation Accuracy: 34.65%Loss: 1.6782  Validation Accuracy: 32.05%Loss: 1.6385  Validation Accuracy: 33.66%Loss: 1.6214  Validation Accuracy: 34.78%Loss: 1.6420  Validation Accuracy: 30.82%Loss: 1.6278  Validation Accuracy: 35.52%Loss: 1.6674  Validation Accuracy: 32.55%Loss: 1.6314  Validation Accuracy: 33.42%Loss: 1.6111  Validation Accuracy: 35.40%Loss: 1.6306  Validation Accuracy: 30.94%Loss: 1.6167  Validation Accuracy: 36.51%Loss: 1.6594  Validation Accuracy: 33.04%Loss: 1.6199  Validation Accuracy: 33.42%Loss: 1.6015  Validation Accuracy: 35.15%Loss: 1.6202  Validation Accuracy: 30.82%Loss: 1.6059  Validation Accuracy: 35.77%Loss: 1.6516  Validation Accuracy: 33.29%Loss: 1.6084  Validation Accuracy: 34.16%Loss: 1.5915  Validation Accuracy: 35.77%Loss: 1.6096  Validation Accuracy: 31.81%Loss: 1.5953  Validation Accuracy: 37.13%Loss: 1.6431  Validation Accuracy: 33.79%Loss: 1.5993  Validation Accuracy: 34.90%Loss: 1.5826  Validation Accuracy: 35.40%Loss: 1.6001  Validation Accuracy: 33.17%Loss: 1.5869  Validation Accuracy: 36.26%Loss: 1.6344  Validation Accuracy: 33.91%Loss: 1.5872  Validation Accuracy: 35.40%Loss: 1.5741  Validation Accuracy: 35.02%Loss: 1.5906  Validation Accuracy: 33.42%Loss: 1.5773  Validation Accuracy: 36.26%Loss: 1.6278  Validation Accuracy: 34.41%Loss: 1.5791  Validation Accuracy: 36.76%Loss: 1.5659  Validation Accuracy: 35.02%Loss: 1.5803  Validation Accuracy: 34.90%Loss: 1.5715  Validation Accuracy: 37.87%Loss: 1.6196  Validation Accuracy: 34.16%Loss: 1.5687  Validation Accuracy: 36.14%Loss: 1.5579  Validation Accuracy: 36.26%Loss: 1.5705  Validation Accuracy: 34.78%Loss: 1.5616  Validation Accuracy: 37.50%Loss: 1.6139  Validation Accuracy: 35.15%Loss: 1.5578  Validation Accuracy: 36.88%Loss: 1.5511  Validation Accuracy: 35.77%Loss: 1.5634  Validation Accuracy: 33.91%Loss: 1.5553  Validation Accuracy: 37.87%Loss: 1.6059  Validation Accuracy: 34.65%Loss: 1.5527  Validation Accuracy: 37.13%Loss: 1.5435  Validation Accuracy: 36.01%Loss: 1.5546  Validation Accuracy: 34.90%Loss: 1.5481  Validation Accuracy: 37.87%Loss: 1.5997  Validation Accuracy: 35.52%Loss: 1.5427  Validation Accuracy: 36.88%Loss: 1.5371  Validation Accuracy: 35.77%Loss: 1.5474  Validation Accuracy: 34.53%Loss: 1.5416  Validation Accuracy: 37.75%Loss: 1.5930  Validation Accuracy: 35.27%Loss: 1.5357  Validation Accuracy: 37.87%Loss: 1.5326  Validation Accuracy: 36.26%Loss: 1.5389  Validation Accuracy: 35.64%Loss: 1.5366  Validation Accuracy: 38.49%Loss: 1.5880  Validation Accuracy: 35.77%Loss: 1.5250  Validation Accuracy: 38.49%Loss: 1.5246  Validation Accuracy: 36.14%Loss: 1.5379  Validation Accuracy: 36.14%Loss: 1.5304  Validation Accuracy: 38.99%Loss: 1.5822  Validation Accuracy: 36.51%Loss: 1.5204  Validation Accuracy: 38.37%Loss: 1.5194  Validation Accuracy: 36.39%Loss: 1.5299  Validation Accuracy: 37.00%Loss: 1.5239  Validation Accuracy: 39.48%Loss: 1.5740  Validation Accuracy: 36.51%Loss: 1.5126  Validation Accuracy: 38.00%Loss: 1.5138  Validation Accuracy: 36.51%Loss: 1.5209  Validation Accuracy: 37.50%Loss: 1.5190  Validation Accuracy: 40.22%Loss: 1.5687  Validation Accuracy: 36.88%Loss: 1.5045  Validation Accuracy: 38.49%Loss: 1.5078  Validation Accuracy: 36.26%Loss: 1.5157  Validation Accuracy: 37.87%Loss: 1.5123  Validation Accuracy: 39.60%Loss: 1.5619  Validation Accuracy: 37.13%Loss: 1.4970  Validation Accuracy: 38.37%Loss: 1.5009  Validation Accuracy: 36.63%Loss: 1.5132  Validation Accuracy: 38.86%Loss: 1.5088  Validation Accuracy: 40.59%Loss: 1.5570  Validation Accuracy: 37.62%Loss: 1.4915  Validation Accuracy: 38.49%Loss: 1.5016  Validation Accuracy: 35.77%Loss: 1.5126  Validation Accuracy: 38.86%Loss: 1.5046  Validation Accuracy: 40.59%Loss: 1.5516  Validation Accuracy: 37.50%Loss: 1.4841  Validation Accuracy: 38.86%Loss: 1.4924  Validation Accuracy: 36.01%Loss: 1.5110  Validation Accuracy: 39.73%Loss: 1.5046  Validation Accuracy: 41.09%Loss: 1.5486  Validation Accuracy: 39.11%Loss: 1.4745  Validation Accuracy: 39.36%Loss: 1.4855  Validation Accuracy: 36.26%Loss: 1.4992  Validation Accuracy: 39.85%Loss: 1.4990  Validation Accuracy: 40.59%Loss: 1.5448  Validation Accuracy: 38.24%Loss: 1.4704  Validation Accuracy: 39.73%Loss: 1.4778  Validation Accuracy: 36.63%Loss: 1.4905  Validation Accuracy: 40.72%Loss: 1.4935  Validation Accuracy: 42.08%Loss: 1.5418  Validation Accuracy: 40.10%Loss: 1.4648  Validation Accuracy: 40.97%Loss: 1.4704  Validation Accuracy: 37.00%Loss: 1.4845  Validation Accuracy: 41.58%Loss: 1.4918  Validation Accuracy: 41.58%Loss: 1.5378  Validation Accuracy: 39.23%Loss: 1.4584  Validation Accuracy: 41.34%Loss: 1.4661  Validation Accuracy: 37.50%Loss: 1.4802  Validation Accuracy: 41.71%Loss: 1.4827  Validation Accuracy: 41.71%Loss: 1.5293  Validation Accuracy: 39.48%Loss: 1.4544  Validation Accuracy: 41.46%Loss: 1.4616  Validation Accuracy: 38.00%Loss: 1.4728  Validation Accuracy: 41.83%Loss: 1.4781  Validation Accuracy: 42.45%Loss: 1.5253  Validation Accuracy: 39.60%Loss: 1.4508  Validation Accuracy: 42.82%Loss: 1.4571  Validation Accuracy: 38.74%Loss: 1.4655  Validation Accuracy: 42.57%Loss: 1.4735  Validation Accuracy: 42.45%Loss: 1.5203  Validation Accuracy: 40.84%Loss: 1.4465  Validation Accuracy: 42.70%Loss: 1.4539  Validation Accuracy: 38.99%Loss: 1.4601  Validation Accuracy: 43.44%Loss: 1.4648  Validation Accuracy: 41.83%Loss: 1.5076  Validation Accuracy: 40.47%Loss: 1.4358  Validation Accuracy: 44.18%Loss: 1.4451  Validation Accuracy: 39.48%Loss: 1.4542  Validation Accuracy: 43.81%Loss: 1.4604  Validation Accuracy: 43.32%Loss: 1.5006  Validation Accuracy: 41.09%Loss: 1.4307  Validation Accuracy: 43.81%Loss: 1.4410  Validation Accuracy: 40.35%Loss: 1.4480  Validation Accuracy: 44.31%Loss: 1.4552  Validation Accuracy: 42.95%Loss: 1.4959  Validation Accuracy: 40.47%Loss: 1.4236  Validation Accuracy: 44.18%Loss: 1.4358  Validation Accuracy: 39.85%Loss: 1.4425  Validation Accuracy: 44.31%Loss: 1.4499  Validation Accuracy: 43.69%Loss: 1.4898  Validation Accuracy: 41.46%Loss: 1.4170  Validation Accuracy: 45.05%Loss: 1.4301  Validation Accuracy: 39.85%Loss: 1.4368  Validation Accuracy: 45.54%Loss: 1.4434  Validation Accuracy: 43.32%Loss: 1.4814  Validation Accuracy: 42.45%Loss: 1.4115  Validation Accuracy: 45.92%Loss: 1.4249  Validation Accuracy: 40.72%Loss: 1.4322  Validation Accuracy: 45.92%Loss: 1.4386  Validation Accuracy: 42.95%Loss: 1.4757  Validation Accuracy: 42.95%Loss: 1.4055  Validation Accuracy: 45.67%Loss: 1.4202  Validation Accuracy: 41.83%Loss: 1.4261  Validation Accuracy: 46.04%Loss: 1.4328  Validation Accuracy: 43.19%Loss: 1.4690  Validation Accuracy: 43.32%Loss: 1.3988  Validation Accuracy: 46.04%Loss: 1.4142  Validation Accuracy: 41.21%Loss: 1.4196  Validation Accuracy: 45.92%Loss: 1.4264  Validation Accuracy: 44.18%Loss: 1.4627  Validation Accuracy: 43.44%Loss: 1.3912  Validation Accuracy: 46.04%Loss: 1.4084  Validation Accuracy: 41.34%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, CIFAR-10 Batch 4:  oss: 1.4148  Validation Accuracy: 46.91%Loss: 1.4243  Validation Accuracy: 44.06%Loss: 1.4573  Validation Accuracy: 43.44%Loss: 1.3855  Validation Accuracy: 45.92%Loss: 1.4028  Validation Accuracy: 41.34%Loss: 1.4085  Validation Accuracy: 46.53%Loss: 1.4184  Validation Accuracy: 44.80%Loss: 1.4508  Validation Accuracy: 43.56%Loss: 1.3785  Validation Accuracy: 46.41%Loss: 1.3962  Validation Accuracy: 41.46%Loss: 1.4006  Validation Accuracy: 47.40%Loss: 1.4121  Validation Accuracy: 45.67%Loss: 1.4440  Validation Accuracy: 43.69%Loss: 1.3726  Validation Accuracy: 46.91%Loss: 1.3921  Validation Accuracy: 42.95%Loss: 1.3962  Validation Accuracy: 48.14%Loss: 1.4049  Validation Accuracy: 45.79%Loss: 1.4396  Validation Accuracy: 44.18%Loss: 1.3666  Validation Accuracy: 47.77%Loss: 1.3882  Validation Accuracy: 42.70%Loss: 1.3895  Validation Accuracy: 48.27%Loss: 1.4011  Validation Accuracy: 46.16%Loss: 1.4356  Validation Accuracy: 44.55%Loss: 1.3608  Validation Accuracy: 47.40%Loss: 1.3815  Validation Accuracy: 43.19%Loss: 1.3849  Validation Accuracy: 48.51%Loss: 1.3949  Validation Accuracy: 45.42%Loss: 1.4290  Validation Accuracy: 43.81%Loss: 1.3550  Validation Accuracy: 47.77%Loss: 1.3764  Validation Accuracy: 43.94%Loss: 1.3796  Validation Accuracy: 48.51%Loss: 1.3895  Validation Accuracy: 45.79%Loss: 1.4225  Validation Accuracy: 44.68%Loss: 1.3481  Validation Accuracy: 47.90%Loss: 1.3715  Validation Accuracy: 44.68%Loss: 1.3728  Validation Accuracy: 48.27%Loss: 1.3825  Validation Accuracy: 45.92%Loss: 1.4157  Validation Accuracy: 44.68%Loss: 1.3419  Validation Accuracy: 48.27%Loss: 1.3669  Validation Accuracy: 44.43%Loss: 1.3644  Validation Accuracy: 49.26%Loss: 1.3732  Validation Accuracy: 46.29%Loss: 1.4083  Validation Accuracy: 44.80%Loss: 1.3347  Validation Accuracy: 48.64%Loss: 1.3596  Validation Accuracy: 45.05%Loss: 1.3593  Validation Accuracy: 50.12%Loss: 1.3713  Validation Accuracy: 46.53%Loss: 1.4060  Validation Accuracy: 44.55%Loss: 1.3283  Validation Accuracy: 49.75%Loss: 1.3551  Validation Accuracy: 45.54%Loss: 1.3536  Validation Accuracy: 49.13%Loss: 1.3653  Validation Accuracy: 46.78%Loss: 1.3952  Validation Accuracy: 45.05%Loss: 1.3190  Validation Accuracy: 49.13%Loss: 1.3485  Validation Accuracy: 45.79%Loss: 1.3460  Validation Accuracy: 50.12%Loss: 1.3565  Validation Accuracy: 47.52%Loss: 1.3903  Validation Accuracy: 45.67%Loss: 1.3114  Validation Accuracy: 49.75%Loss: 1.3406  Validation Accuracy: 46.53%Loss: 1.3393  Validation Accuracy: 49.26%Loss: 1.3500  Validation Accuracy: 48.02%Loss: 1.3828  Validation Accuracy: 45.17%Loss: 1.3057  Validation Accuracy: 49.75%Loss: 1.3352  Validation Accuracy: 47.28%Loss: 1.3315  Validation Accuracy: 49.26%Loss: 1.3447  Validation Accuracy: 47.77%Loss: 1.3744  Validation Accuracy: 46.41%Loss: 1.2974  Validation Accuracy: 50.00%Loss: 1.3301  Validation Accuracy: 48.02%Loss: 1.3272  Validation Accuracy: 49.38%Loss: 1.3393  Validation Accuracy: 48.02%Loss: 1.3706  Validation Accuracy: 46.16%Loss: 1.2907  Validation Accuracy: 50.37%Loss: 1.3231  Validation Accuracy: 47.90%Loss: 1.3205  Validation Accuracy: 49.50%Loss: 1.3327  Validation Accuracy: 48.14%Loss: 1.3650  Validation Accuracy: 46.66%Loss: 1.2819  Validation Accuracy: 50.74%Loss: 1.3150  Validation Accuracy: 48.39%Loss: 1.3131  Validation Accuracy: 49.88%Loss: 1.3246  Validation Accuracy: 48.39%Loss: 1.3581  Validation Accuracy: 47.65%Loss: 1.2762  Validation Accuracy: 50.37%Loss: 1.3106  Validation Accuracy: 48.76%Loss: 1.3063  Validation Accuracy: 49.63%Loss: 1.3177  Validation Accuracy: 48.02%Loss: 1.3509  Validation Accuracy: 47.65%Loss: 1.2668  Validation Accuracy: 51.49%Loss: 1.3032  Validation Accuracy: 49.01%Loss: 1.2999  Validation Accuracy: 49.75%Loss: 1.3076  Validation Accuracy: 48.39%Loss: 1.3430  Validation Accuracy: 47.28%Loss: 1.2608  Validation Accuracy: 51.49%Loss: 1.2962  Validation Accuracy: 50.00%Loss: 1.2905  Validation Accuracy: 50.00%Loss: 1.2996  Validation Accuracy: 49.38%Loss: 1.3361  Validation Accuracy: 47.52%Loss: 1.2540  Validation Accuracy: 51.98%Loss: 1.2897  Validation Accuracy: 49.50%Loss: 1.2837  Validation Accuracy: 50.37%Loss: 1.2950  Validation Accuracy: 49.88%Loss: 1.3285  Validation Accuracy: 47.40%Loss: 1.2467  Validation Accuracy: 52.60%Loss: 1.2821  Validation Accuracy: 49.75%Loss: 1.2767  Validation Accuracy: 50.12%Loss: 1.2879  Validation Accuracy: 50.25%Loss: 1.3212  Validation Accuracy: 48.39%Loss: 1.2403  Validation Accuracy: 53.34%Loss: 1.2736  Validation Accuracy: 50.25%Loss: 1.2700  Validation Accuracy: 50.62%Loss: 1.2811  Validation Accuracy: 50.12%Loss: 1.3162  Validation Accuracy: 48.02%Loss: 1.2343  Validation Accuracy: 52.97%Loss: 1.2674  Validation Accuracy: 50.50%Loss: 1.2620  Validation Accuracy: 50.74%Loss: 1.2743  Validation Accuracy: 50.00%Loss: 1.3075  Validation Accuracy: 47.65%Loss: 1.2260  Validation Accuracy: 53.59%Loss: 1.2588  Validation Accuracy: 50.62%Loss: 1.2549  Validation Accuracy: 51.24%Loss: 1.2658  Validation Accuracy: 50.25%Loss: 1.3025  Validation Accuracy: 48.02%Loss: 1.2203  Validation Accuracy: 53.59%Loss: 1.2557  Validation Accuracy: 50.50%Loss: 1.2485  Validation Accuracy: 50.99%Loss: 1.2618  Validation Accuracy: 50.25%Loss: 1.2953  Validation Accuracy: 48.14%Loss: 1.2138  Validation Accuracy: 53.34%Loss: 1.2494  Validation Accuracy: 50.37%Loss: 1.2416  Validation Accuracy: 50.87%Loss: 1.2556  Validation Accuracy: 50.12%Loss: 1.2867  Validation Accuracy: 48.76%Loss: 1.2093  Validation Accuracy: 53.96%Loss: 1.2418  Validation Accuracy: 51.61%Loss: 1.2363  Validation Accuracy: 51.36%Loss: 1.2482  Validation Accuracy: 50.74%Loss: 1.2814  Validation Accuracy: 48.76%Loss: 1.2024  Validation Accuracy: 54.08%Loss: 1.2358  Validation Accuracy: 50.99%Loss: 1.2290  Validation Accuracy: 50.87%Loss: 1.2439  Validation Accuracy: 50.37%Loss: 1.2755  Validation Accuracy: 49.26%Loss: 1.1995  Validation Accuracy: 53.71%Loss: 1.2281  Validation Accuracy: 52.35%Loss: 1.2226  Validation Accuracy: 51.61%Loss: 1.2387  Validation Accuracy: 51.36%Loss: 1.2671  Validation Accuracy: 49.38%Loss: 1.1916  Validation Accuracy: 54.21%Loss: 1.2241  Validation Accuracy: 51.61%Loss: 1.2165  Validation Accuracy: 52.35%Loss: 1.2317  Validation Accuracy: 50.99%Loss: 1.2597  Validation Accuracy: 49.50%Loss: 1.1859  Validation Accuracy: 53.71%Loss: 1.2153  Validation Accuracy: 51.86%Loss: 1.2097  Validation Accuracy: 52.97%Loss: 1.2258  Validation Accuracy: 51.86%Loss: 1.2538  Validation Accuracy: 49.63%Loss: 1.1819  Validation Accuracy: 54.08%Loss: 1.2117  Validation Accuracy: 51.98%Loss: 1.2044  Validation Accuracy: 52.23%Loss: 1.2152  Validation Accuracy: 52.10%Loss: 1.2459  Validation Accuracy: 49.88%Loss: 1.1756  Validation Accuracy: 54.83%Loss: 1.2040  Validation Accuracy: 52.97%Loss: 1.1984  Validation Accuracy: 52.72%Loss: 1.2128  Validation Accuracy: 52.10%Loss: 1.2398  Validation Accuracy: 50.62%Loss: 1.1713  Validation Accuracy: 54.46%Loss: 1.1998  Validation Accuracy: 53.47%Loss: 1.1935  Validation Accuracy: 52.72%Loss: 1.2063  Validation Accuracy: 51.98%Loss: 1.2331  Validation Accuracy: 51.24%Loss: 1.1651  Validation Accuracy: 54.95%Loss: 1.1931  Validation Accuracy: 53.22%Loss: 1.1869  Validation Accuracy: 53.34%Loss: 1.2011  Validation Accuracy: 52.10%Loss: 1.2256  Validation Accuracy: 52.10%Loss: 1.1649  Validation Accuracy: 55.69%Loss: 1.1882  Validation Accuracy: 53.47%Loss: 1.1806  Validation Accuracy: 53.71%Loss: 1.1960  Validation Accuracy: 52.85%Loss: 1.2181  Validation Accuracy: 51.86%Loss: 1.1585  Validation Accuracy: 55.69%Loss: 1.1822  Validation Accuracy: 54.08%Loss: 1.1756  Validation Accuracy: 54.21%Loss: 1.1886  Validation Accuracy: 53.47%Loss: 1.2110  Validation Accuracy: 52.35%Loss: 1.1533  Validation Accuracy: 56.06%Loss: 1.1778  Validation Accuracy: 53.84%Loss: 1.1685  Validation Accuracy: 54.95%Loss: 1.1832  Validation Accuracy: 52.35%Loss: 1.2061  Validation Accuracy: 51.61%Loss: 1.1501  Validation Accuracy: 55.32%Loss: 1.1746  Validation Accuracy: 54.21%Loss: 1.1644  Validation Accuracy: 54.58%Loss: 1.1787  Validation Accuracy: 53.47%Loss: 1.1997  Validation Accuracy: 53.22%Loss: 1.1440  Validation Accuracy: 56.06%Loss: 1.1669  Validation Accuracy: 54.21%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160, CIFAR-10 Batch 4:  Loss: 1.1574  Validation Accuracy: 54.95%Loss: 1.1711  Validation Accuracy: 53.59%Loss: 1.1939  Validation Accuracy: 53.09%Loss: 1.1411  Validation Accuracy: 55.82%Loss: 1.1618  Validation Accuracy: 54.46%Loss: 1.1508  Validation Accuracy: 55.32%Loss: 1.1670  Validation Accuracy: 53.96%Loss: 1.1877  Validation Accuracy: 52.85%Loss: 1.1355  Validation Accuracy: 55.94%Loss: 1.1545  Validation Accuracy: 54.58%Loss: 1.1459  Validation Accuracy: 56.31%Loss: 1.1627  Validation Accuracy: 54.08%Loss: 1.1815  Validation Accuracy: 53.71%Loss: 1.1310  Validation Accuracy: 56.68%Loss: 1.1514  Validation Accuracy: 53.84%Loss: 1.1425  Validation Accuracy: 55.94%Loss: 1.1566  Validation Accuracy: 54.33%Loss: 1.1768  Validation Accuracy: 53.71%Loss: 1.1272  Validation Accuracy: 56.56%Loss: 1.1448  Validation Accuracy: 54.58%Loss: 1.1352  Validation Accuracy: 55.82%Loss: 1.1532  Validation Accuracy: 54.58%Loss: 1.1709  Validation Accuracy: 53.84%Loss: 1.1221  Validation Accuracy: 55.94%Loss: 1.1397  Validation Accuracy: 55.94%Loss: 1.1284  Validation Accuracy: 56.19%Loss: 1.1489  Validation Accuracy: 53.84%Loss: 1.1671  Validation Accuracy: 53.96%Loss: 1.1175  Validation Accuracy: 56.31%Loss: 1.1349  Validation Accuracy: 54.95%Loss: 1.1241  Validation Accuracy: 56.81%Loss: 1.1435  Validation Accuracy: 54.95%Loss: 1.1612  Validation Accuracy: 54.21%Loss: 1.1153  Validation Accuracy: 56.68%Loss: 1.1285  Validation Accuracy: 56.06%Loss: 1.1190  Validation Accuracy: 56.68%Loss: 1.1386  Validation Accuracy: 54.46%Loss: 1.1553  Validation Accuracy: 54.70%Loss: 1.1098  Validation Accuracy: 56.19%Loss: 1.1261  Validation Accuracy: 55.82%Loss: 1.1152  Validation Accuracy: 57.05%Loss: 1.1331  Validation Accuracy: 54.95%Loss: 1.1508  Validation Accuracy: 55.07%Loss: 1.1081  Validation Accuracy: 56.31%Loss: 1.1214  Validation Accuracy: 55.57%Loss: 1.1106  Validation Accuracy: 57.55%Loss: 1.1298  Validation Accuracy: 55.69%Loss: 1.1460  Validation Accuracy: 55.69%Loss: 1.1012  Validation Accuracy: 56.56%Loss: 1.1178  Validation Accuracy: 56.31%Loss: 1.1036  Validation Accuracy: 57.55%Loss: 1.1257  Validation Accuracy: 54.83%Loss: 1.1446  Validation Accuracy: 55.57%Loss: 1.0969  Validation Accuracy: 57.05%Loss: 1.1135  Validation Accuracy: 56.68%Loss: 1.0990  Validation Accuracy: 57.67%Loss: 1.1203  Validation Accuracy: 55.45%Loss: 1.1373  Validation Accuracy: 56.44%Loss: 1.0937  Validation Accuracy: 57.43%Loss: 1.1095  Validation Accuracy: 57.18%Loss: 1.0925  Validation Accuracy: 58.54%Loss: 1.1159  Validation Accuracy: 55.57%Loss: 1.1336  Validation Accuracy: 55.57%Loss: 1.0884  Validation Accuracy: 57.30%Loss: 1.1043  Validation Accuracy: 57.18%Loss: 1.0903  Validation Accuracy: 57.92%Loss: 1.1129  Validation Accuracy: 55.69%Loss: 1.1268  Validation Accuracy: 55.94%Loss: 1.0849  Validation Accuracy: 57.30%Loss: 1.1012  Validation Accuracy: 57.05%Loss: 1.0837  Validation Accuracy: 58.04%Loss: 1.1070  Validation Accuracy: 56.19%Loss: 1.1241  Validation Accuracy: 56.06%Loss: 1.0806  Validation Accuracy: 57.18%Loss: 1.0955  Validation Accuracy: 57.43%Loss: 1.0811  Validation Accuracy: 58.54%Loss: 1.1030  Validation Accuracy: 57.18%Loss: 1.1197  Validation Accuracy: 56.06%Loss: 1.0755  Validation Accuracy: 56.93%Loss: 1.0940  Validation Accuracy: 57.30%Loss: 1.0744  Validation Accuracy: 58.54%Loss: 1.1003  Validation Accuracy: 56.56%Loss: 1.1151  Validation Accuracy: 56.31%Loss: 1.0710  Validation Accuracy: 57.55%Loss: 1.0887  Validation Accuracy: 57.80%Loss: 1.0691  Validation Accuracy: 59.28%Loss: 1.0966  Validation Accuracy: 57.30%Loss: 1.1112  Validation Accuracy: 56.31%Loss: 1.0698  Validation Accuracy: 58.42%Loss: 1.0874  Validation Accuracy: 58.17%Loss: 1.0693  Validation Accuracy: 58.66%Loss: 1.0932  Validation Accuracy: 57.80%Loss: 1.1068  Validation Accuracy: 55.57%Loss: 1.0668  Validation Accuracy: 58.42%Loss: 1.0844  Validation Accuracy: 57.92%Loss: 1.0630  Validation Accuracy: 59.41%Loss: 1.0887  Validation Accuracy: 56.93%Loss: 1.1035  Validation Accuracy: 56.31%Loss: 1.0631  Validation Accuracy: 58.66%Loss: 1.0794  Validation Accuracy: 58.17%Loss: 1.0588  Validation Accuracy: 58.42%Loss: 1.0854  Validation Accuracy: 58.04%Loss: 1.0992  Validation Accuracy: 56.68%Loss: 1.0585  Validation Accuracy: 58.54%Loss: 1.0759  Validation Accuracy: 58.29%Loss: 1.0549  Validation Accuracy: 59.16%Loss: 1.0811  Validation Accuracy: 58.42%Loss: 1.0932  Validation Accuracy: 56.56%Loss: 1.0520  Validation Accuracy: 58.54%Loss: 1.0697  Validation Accuracy: 58.42%Loss: 1.0512  Validation Accuracy: 59.41%Loss: 1.0787  Validation Accuracy: 58.42%Loss: 1.0891  Validation Accuracy: 56.93%Loss: 1.0503  Validation Accuracy: 59.03%Loss: 1.0701  Validation Accuracy: 57.92%Loss: 1.0479  Validation Accuracy: 59.53%Loss: 1.0734  Validation Accuracy: 58.54%Loss: 1.0861  Validation Accuracy: 56.31%Loss: 1.0473  Validation Accuracy: 59.16%Loss: 1.0660  Validation Accuracy: 59.28%Loss: 1.0442  Validation Accuracy: 59.65%Loss: 1.0706  Validation Accuracy: 59.03%Loss: 1.0798  Validation Accuracy: 57.80%Loss: 1.0423  Validation Accuracy: 59.28%Loss: 1.0626  Validation Accuracy: 59.28%Loss: 1.0437  Validation Accuracy: 59.65%Loss: 1.0710  Validation Accuracy: 59.53%Loss: 1.0776  Validation Accuracy: 57.92%Loss: 1.0404  Validation Accuracy: 59.41%Loss: 1.0648  Validation Accuracy: 57.30%Loss: 1.0418  Validation Accuracy: 60.02%Loss: 1.0653  Validation Accuracy: 59.41%Loss: 1.0750  Validation Accuracy: 58.04%Loss: 1.0359  Validation Accuracy: 59.78%Loss: 1.0568  Validation Accuracy: 58.54%Loss: 1.0378  Validation Accuracy: 60.02%Loss: 1.0651  Validation Accuracy: 59.16%Loss: 1.0698  Validation Accuracy: 57.30%Loss: 1.0324  Validation Accuracy: 59.65%Loss: 1.0577  Validation Accuracy: 58.91%Loss: 1.0414  Validation Accuracy: 59.90%Loss: 1.0634  Validation Accuracy: 58.79%Loss: 1.0674  Validation Accuracy: 58.17%Loss: 1.0257  Validation Accuracy: 59.53%Loss: 1.0531  Validation Accuracy: 59.16%Loss: 1.0347  Validation Accuracy: 60.40%Loss: 1.0639  Validation Accuracy: 59.28%Loss: 1.0652  Validation Accuracy: 57.92%Loss: 1.0231  Validation Accuracy: 60.15%Loss: 1.0472  Validation Accuracy: 60.27%Loss: 1.0318  Validation Accuracy: 60.77%Loss: 1.0578  Validation Accuracy: 59.65%Loss: 1.0679  Validation Accuracy: 58.29%Loss: 1.0207  Validation Accuracy: 60.52%Loss: 1.0431  Validation Accuracy: 60.52%Loss: 1.0219  Validation Accuracy: 60.40%Loss: 1.0521  Validation Accuracy: 59.53%Loss: 1.0609  Validation Accuracy: 59.03%Loss: 1.0146  Validation Accuracy: 59.90%Loss: 1.0379  Validation Accuracy: 59.65%Loss: 1.0218  Validation Accuracy: 60.64%Loss: 1.0525  Validation Accuracy: 60.27%Loss: 1.0561  Validation Accuracy: 59.16%Loss: 1.0108  Validation Accuracy: 60.64%Loss: 1.0382  Validation Accuracy: 59.78%Loss: 1.0199  Validation Accuracy: 61.63%Loss: 1.0515  Validation Accuracy: 60.15%Loss: 1.0541  Validation Accuracy: 59.03%Loss: 1.0098  Validation Accuracy: 60.64%Loss: 1.0345  Validation Accuracy: 60.64%Loss: 1.0129  Validation Accuracy: 61.14%Loss: 1.0480  Validation Accuracy: 60.40%Loss: 1.0530  Validation Accuracy: 58.66%Loss: 1.0051  Validation Accuracy: 60.15%Loss: 1.0300  Validation Accuracy: 60.52%Loss: 1.0100  Validation Accuracy: 60.77%Loss: 1.0390  Validation Accuracy: 60.15%Loss: 1.0469  Validation Accuracy: 59.16%Loss: 1.0014  Validation Accuracy: 60.15%Loss: 1.0269  Validation Accuracy: 60.40%Loss: 1.0082  Validation Accuracy: 61.39%Loss: 1.0356  Validation Accuracy: 59.41%Loss: 1.0418  Validation Accuracy: 59.16%Loss: 0.9984  Validation Accuracy: 61.14%Loss: 1.0225  Validation Accuracy: 61.01%Loss: 1.0042  Validation Accuracy: 61.51%Loss: 1.0332  Validation Accuracy: 60.52%Loss: 1.0404  Validation Accuracy: 59.28%Loss: 0.9962  Validation Accuracy: 61.39%Loss: 1.0210  Validation Accuracy: 60.40%Loss: 1.0020  Validation Accuracy: 61.63%Loss: 1.0314  Validation Accuracy: 60.27%Loss: 1.0363  Validation Accuracy: 59.65%Loss: 0.9932  Validation Accuracy: 60.89%Loss: 1.0212  Validation Accuracy: 61.14%Loss: 0.9980  Validation Accuracy: 61.76%Loss: 1.0269  Validation Accuracy: 60.52%Loss: 1.0338  Validation Accuracy: 60.40%Loss: 0.9897  Validation Accuracy: 61.01%Loss: 1.0169  Validation Accuracy: 60.89%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, CIFAR-10 Batch 4:  Loss: 0.9963  Validation Accuracy: 61.51%Loss: 1.0234  Validation Accuracy: 60.64%Loss: 1.0268  Validation Accuracy: 60.40%Loss: 0.9854  Validation Accuracy: 61.88%Loss: 1.0138  Validation Accuracy: 61.01%Loss: 0.9919  Validation Accuracy: 61.26%Loss: 1.0212  Validation Accuracy: 60.15%Loss: 1.0235  Validation Accuracy: 60.64%Loss: 0.9827  Validation Accuracy: 62.38%Loss: 1.0116  Validation Accuracy: 61.39%Loss: 0.9902  Validation Accuracy: 61.76%Loss: 1.0181  Validation Accuracy: 61.01%Loss: 1.0193  Validation Accuracy: 59.78%Loss: 0.9805  Validation Accuracy: 61.88%Loss: 1.0060  Validation Accuracy: 61.01%Loss: 0.9866  Validation Accuracy: 62.38%Loss: 1.0161  Validation Accuracy: 61.51%Loss: 1.0180  Validation Accuracy: 60.02%Loss: 0.9771  Validation Accuracy: 62.25%Loss: 1.0039  Validation Accuracy: 61.63%Loss: 0.9825  Validation Accuracy: 62.13%Loss: 1.0131  Validation Accuracy: 60.89%Loss: 1.0168  Validation Accuracy: 60.15%Loss: 0.9760  Validation Accuracy: 61.76%Loss: 1.0017  Validation Accuracy: 61.51%Loss: 0.9792  Validation Accuracy: 62.13%Loss: 1.0104  Validation Accuracy: 60.64%Loss: 1.0107  Validation Accuracy: 60.64%Loss: 0.9725  Validation Accuracy: 62.38%Loss: 1.0015  Validation Accuracy: 61.63%Loss: 0.9759  Validation Accuracy: 62.50%Loss: 1.0099  Validation Accuracy: 61.39%Loss: 1.0087  Validation Accuracy: 60.64%Loss: 0.9692  Validation Accuracy: 62.38%Loss: 0.9975  Validation Accuracy: 61.14%Loss: 0.9747  Validation Accuracy: 62.25%Loss: 1.0074  Validation Accuracy: 61.14%Loss: 1.0073  Validation Accuracy: 60.64%Loss: 0.9657  Validation Accuracy: 61.76%Loss: 0.9936  Validation Accuracy: 61.88%Loss: 0.9717  Validation Accuracy: 62.38%Loss: 1.0054  Validation Accuracy: 61.39%Loss: 0.9997  Validation Accuracy: 60.40%Loss: 0.9636  Validation Accuracy: 62.87%Loss: 0.9907  Validation Accuracy: 61.88%Loss: 0.9702  Validation Accuracy: 62.75%Loss: 1.0022  Validation Accuracy: 61.51%Loss: 0.9968  Validation Accuracy: 60.15%Loss: 0.9590  Validation Accuracy: 62.25%Loss: 0.9865  Validation Accuracy: 61.63%Loss: 0.9672  Validation Accuracy: 62.87%Loss: 0.9996  Validation Accuracy: 62.00%Loss: 0.9960  Validation Accuracy: 60.77%Loss: 0.9556  Validation Accuracy: 62.75%Loss: 0.9848  Validation Accuracy: 62.13%Loss: 0.9648  Validation Accuracy: 62.75%Loss: 0.9996  Validation Accuracy: 61.63%Loss: 0.9920  Validation Accuracy: 61.01%Loss: 0.9529  Validation Accuracy: 62.75%Loss: 0.9814  Validation Accuracy: 61.63%Loss: 0.9629  Validation Accuracy: 63.00%Loss: 0.9943  Validation Accuracy: 62.00%Loss: 0.9887  Validation Accuracy: 61.01%Loss: 0.9504  Validation Accuracy: 62.75%Loss: 0.9788  Validation Accuracy: 61.88%Loss: 0.9617  Validation Accuracy: 62.87%Loss: 0.9916  Validation Accuracy: 61.26%Loss: 0.9866  Validation Accuracy: 60.77%Loss: 0.9493  Validation Accuracy: 63.12%Loss: 0.9761  Validation Accuracy: 61.76%Loss: 0.9580  Validation Accuracy: 63.37%Loss: 0.9910  Validation Accuracy: 61.51%Loss: 0.9823  Validation Accuracy: 61.63%Loss: 0.9464  Validation Accuracy: 62.13%Loss: 0.9744  Validation Accuracy: 62.50%Loss: 0.9567  Validation Accuracy: 63.99%Loss: 0.9860  Validation Accuracy: 61.88%Loss: 0.9807  Validation Accuracy: 61.76%Loss: 0.9451  Validation Accuracy: 62.62%Loss: 0.9701  Validation Accuracy: 62.75%Loss: 0.9550  Validation Accuracy: 63.37%Loss: 0.9849  Validation Accuracy: 61.76%Loss: 0.9783  Validation Accuracy: 61.88%Loss: 0.9411  Validation Accuracy: 63.12%Loss: 0.9689  Validation Accuracy: 62.62%Loss: 0.9535  Validation Accuracy: 63.37%Loss: 0.9839  Validation Accuracy: 61.63%Loss: 0.9758  Validation Accuracy: 62.13%Loss: 0.9399  Validation Accuracy: 62.50%Loss: 0.9680  Validation Accuracy: 63.12%Loss: 0.9498  Validation Accuracy: 63.86%Loss: 0.9823  Validation Accuracy: 61.88%Loss: 0.9748  Validation Accuracy: 60.52%Loss: 0.9379  Validation Accuracy: 62.62%Loss: 0.9639  Validation Accuracy: 62.50%Loss: 0.9493  Validation Accuracy: 64.23%Loss: 0.9794  Validation Accuracy: 61.76%Loss: 0.9702  Validation Accuracy: 62.13%Loss: 0.9353  Validation Accuracy: 63.00%Loss: 0.9608  Validation Accuracy: 62.75%Loss: 0.9459  Validation Accuracy: 64.36%Loss: 0.9789  Validation Accuracy: 62.13%Loss: 0.9691  Validation Accuracy: 62.62%Loss: 0.9327  Validation Accuracy: 63.12%Loss: 0.9592  Validation Accuracy: 63.00%Loss: 0.9438  Validation Accuracy: 64.36%Loss: 0.9763  Validation Accuracy: 62.13%Loss: 0.9675  Validation Accuracy: 61.26%Loss: 0.9297  Validation Accuracy: 63.37%Loss: 0.9567  Validation Accuracy: 63.12%Loss: 0.9429  Validation Accuracy: 64.98%Loss: 0.9752  Validation Accuracy: 61.88%Loss: 0.9636  Validation Accuracy: 61.51%Loss: 0.9257  Validation Accuracy: 63.37%Loss: 0.9541  Validation Accuracy: 62.62%Loss: 0.9396  Validation Accuracy: 63.86%Loss: 0.9718  Validation Accuracy: 61.88%Loss: 0.9584  Validation Accuracy: 62.00%Loss: 0.9242  Validation Accuracy: 63.24%Loss: 0.9521  Validation Accuracy: 63.74%Loss: 0.9375  Validation Accuracy: 64.23%Loss: 0.9703  Validation Accuracy: 62.13%Loss: 0.9563  Validation Accuracy: 62.00%Loss: 0.9216  Validation Accuracy: 63.12%Loss: 0.9491  Validation Accuracy: 63.61%Loss: 0.9345  Validation Accuracy: 65.10%Loss: 0.9658  Validation Accuracy: 62.25%Loss: 0.9559  Validation Accuracy: 62.00%Loss: 0.9210  Validation Accuracy: 63.37%Loss: 0.9469  Validation Accuracy: 63.49%Loss: 0.9331  Validation Accuracy: 63.86%Loss: 0.9649  Validation Accuracy: 62.38%Loss: 0.9517  Validation Accuracy: 61.63%Loss: 0.9179  Validation Accuracy: 63.37%Loss: 0.9437  Validation Accuracy: 63.49%Loss: 0.9313  Validation Accuracy: 64.73%Loss: 0.9634  Validation Accuracy: 63.24%Loss: 0.9506  Validation Accuracy: 61.26%Loss: 0.9163  Validation Accuracy: 64.11%Loss: 0.9436  Validation Accuracy: 63.49%Loss: 0.9299  Validation Accuracy: 63.74%Loss: 0.9617  Validation Accuracy: 62.50%Loss: 0.9483  Validation Accuracy: 62.00%Loss: 0.9110  Validation Accuracy: 63.99%Loss: 0.9386  Validation Accuracy: 63.61%Loss: 0.9282  Validation Accuracy: 64.85%Loss: 0.9602  Validation Accuracy: 62.25%Loss: 0.9465  Validation Accuracy: 61.88%Loss: 0.9109  Validation Accuracy: 64.60%Loss: 0.9385  Validation Accuracy: 63.49%Loss: 0.9267  Validation Accuracy: 64.36%Loss: 0.9593  Validation Accuracy: 62.87%Loss: 0.9440  Validation Accuracy: 62.25%Loss: 0.9087  Validation Accuracy: 63.99%Loss: 0.9361  Validation Accuracy: 63.61%Loss: 0.9237  Validation Accuracy: 64.48%Loss: 0.9565  Validation Accuracy: 63.24%Loss: 0.9397  Validation Accuracy: 62.25%Loss: 0.9065  Validation Accuracy: 64.60%Loss: 0.9331  Validation Accuracy: 64.11%Loss: 0.9223  Validation Accuracy: 65.22%Loss: 0.9552  Validation Accuracy: 63.24%Loss: 0.9381  Validation Accuracy: 62.50%Loss: 0.9039  Validation Accuracy: 63.99%Loss: 0.9297  Validation Accuracy: 64.36%Loss: 0.9201  Validation Accuracy: 65.22%Loss: 0.9520  Validation Accuracy: 62.62%Loss: 0.9353  Validation Accuracy: 63.00%Loss: 0.9011  Validation Accuracy: 64.73%Loss: 0.9288  Validation Accuracy: 63.99%Loss: 0.9177  Validation Accuracy: 64.85%Loss: 0.9515  Validation Accuracy: 63.74%Loss: 0.9334  Validation Accuracy: 62.87%Loss: 0.9002  Validation Accuracy: 64.73%Loss: 0.9280  Validation Accuracy: 63.86%Loss: 0.9148  Validation Accuracy: 64.60%Loss: 0.9490  Validation Accuracy: 62.50%Loss: 0.9318  Validation Accuracy: 62.62%Loss: 0.8974  Validation Accuracy: 65.10%Loss: 0.9241  Validation Accuracy: 64.60%Loss: 0.9123  Validation Accuracy: 64.73%Loss: 0.9449  Validation Accuracy: 62.87%Loss: 0.9292  Validation Accuracy: 63.49%Loss: 0.8957  Validation Accuracy: 65.35%Loss: 0.9226  Validation Accuracy: 64.60%Loss: 0.9117  Validation Accuracy: 65.47%Loss: 0.9467  Validation Accuracy: 63.49%Loss: 0.9281  Validation Accuracy: 62.62%Loss: 0.8920  Validation Accuracy: 65.10%Loss: 0.9194  Validation Accuracy: 64.36%Loss: 0.9104  Validation Accuracy: 65.59%Loss: 0.9432  Validation Accuracy: 63.74%Loss: 0.9252  Validation Accuracy: 62.38%Loss: 0.8911  Validation Accuracy: 64.73%Loss: 0.9185  Validation Accuracy: 63.99%Loss: 0.9094  Validation Accuracy: 64.60%Loss: 0.9440  Validation Accuracy: 63.61%Loss: 0.9245  Validation Accuracy: 63.12%Loss: 0.8905  Validation Accuracy: 65.59%Loss: 0.9175  Validation Accuracy: 64.23%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240, CIFAR-10 Batch 4:  Loss: 0.9065  Validation Accuracy: 65.72%Loss: 0.9400  Validation Accuracy: 63.49%Loss: 0.9178  Validation Accuracy: 63.24%Loss: 0.8870  Validation Accuracy: 65.47%Loss: 0.9136  Validation Accuracy: 64.73%Loss: 0.9054  Validation Accuracy: 64.73%Loss: 0.9377  Validation Accuracy: 63.37%Loss: 0.9181  Validation Accuracy: 63.61%Loss: 0.8859  Validation Accuracy: 65.35%Loss: 0.9120  Validation Accuracy: 64.11%Loss: 0.9018  Validation Accuracy: 65.35%Loss: 0.9363  Validation Accuracy: 63.24%Loss: 0.9167  Validation Accuracy: 63.24%Loss: 0.8835  Validation Accuracy: 65.47%Loss: 0.9120  Validation Accuracy: 64.73%Loss: 0.8998  Validation Accuracy: 65.22%Loss: 0.9336  Validation Accuracy: 63.24%Loss: 0.9131  Validation Accuracy: 63.61%Loss: 0.8822  Validation Accuracy: 64.98%Loss: 0.9088  Validation Accuracy: 65.10%Loss: 0.9014  Validation Accuracy: 65.47%Loss: 0.9323  Validation Accuracy: 63.24%Loss: 0.9107  Validation Accuracy: 63.37%Loss: 0.8829  Validation Accuracy: 65.84%Loss: 0.9063  Validation Accuracy: 64.85%Loss: 0.9005  Validation Accuracy: 65.22%Loss: 0.9321  Validation Accuracy: 63.99%Loss: 0.9102  Validation Accuracy: 63.74%Loss: 0.8800  Validation Accuracy: 65.35%Loss: 0.9042  Validation Accuracy: 65.22%Loss: 0.8951  Validation Accuracy: 65.47%Loss: 0.9288  Validation Accuracy: 63.99%Loss: 0.9064  Validation Accuracy: 64.23%Loss: 0.8763  Validation Accuracy: 66.09%Loss: 0.9042  Validation Accuracy: 65.35%Loss: 0.8947  Validation Accuracy: 65.22%Loss: 0.9284  Validation Accuracy: 63.74%Loss: 0.9070  Validation Accuracy: 63.99%Loss: 0.8745  Validation Accuracy: 65.84%Loss: 0.9010  Validation Accuracy: 65.59%Loss: 0.8937  Validation Accuracy: 65.84%Loss: 0.9267  Validation Accuracy: 64.23%Loss: 0.9038  Validation Accuracy: 63.74%Loss: 0.8731  Validation Accuracy: 65.72%Loss: 0.8980  Validation Accuracy: 65.72%Loss: 0.8908  Validation Accuracy: 66.34%Loss: 0.9237  Validation Accuracy: 63.99%Loss: 0.9024  Validation Accuracy: 63.99%Loss: 0.8716  Validation Accuracy: 65.84%Loss: 0.8986  Validation Accuracy: 65.72%Loss: 0.8895  Validation Accuracy: 65.59%Loss: 0.9248  Validation Accuracy: 63.37%Loss: 0.9014  Validation Accuracy: 64.23%Loss: 0.8690  Validation Accuracy: 65.22%Loss: 0.8984  Validation Accuracy: 66.34%Loss: 0.8883  Validation Accuracy: 65.59%Loss: 0.9203  Validation Accuracy: 63.61%Loss: 0.8979  Validation Accuracy: 64.98%Loss: 0.8680  Validation Accuracy: 66.09%Loss: 0.8939  Validation Accuracy: 65.97%Loss: 0.8869  Validation Accuracy: 65.84%Loss: 0.9174  Validation Accuracy: 64.36%Loss: 0.8987  Validation Accuracy: 64.73%Loss: 0.8665  Validation Accuracy: 65.97%Loss: 0.8910  Validation Accuracy: 66.46%Loss: 0.8823  Validation Accuracy: 66.21%Loss: 0.9165  Validation Accuracy: 64.23%Loss: 0.8949  Validation Accuracy: 64.85%Loss: 0.8657  Validation Accuracy: 65.97%Loss: 0.8904  Validation Accuracy: 65.22%Loss: 0.8827  Validation Accuracy: 66.21%Loss: 0.9139  Validation Accuracy: 63.86%Loss: 0.8932  Validation Accuracy: 64.48%Loss: 0.8636  Validation Accuracy: 66.71%Loss: 0.8872  Validation Accuracy: 66.34%Loss: 0.8822  Validation Accuracy: 66.46%Loss: 0.9124  Validation Accuracy: 64.23%Loss: 0.8912  Validation Accuracy: 64.48%Loss: 0.8621  Validation Accuracy: 66.58%Loss: 0.8870  Validation Accuracy: 66.96%Loss: 0.8801  Validation Accuracy: 66.09%Loss: 0.9123  Validation Accuracy: 63.86%Loss: 0.8900  Validation Accuracy: 64.60%Loss: 0.8601  Validation Accuracy: 66.21%Loss: 0.8864  Validation Accuracy: 66.09%Loss: 0.8798  Validation Accuracy: 66.34%Loss: 0.9117  Validation Accuracy: 63.49%Loss: 0.8924  Validation Accuracy: 64.73%Loss: 0.8587  Validation Accuracy: 66.34%Loss: 0.8846  Validation Accuracy: 65.97%Loss: 0.8783  Validation Accuracy: 65.22%Loss: 0.9089  Validation Accuracy: 63.61%Loss: 0.8869  Validation Accuracy: 65.35%Loss: 0.8573  Validation Accuracy: 66.46%Loss: 0.8810  Validation Accuracy: 66.96%Loss: 0.8761  Validation Accuracy: 65.72%Loss: 0.9046  Validation Accuracy: 64.73%Loss: 0.8842  Validation Accuracy: 65.47%Loss: 0.8571  Validation Accuracy: 66.83%Loss: 0.8797  Validation Accuracy: 67.33%Loss: 0.8732  Validation Accuracy: 65.97%Loss: 0.9042  Validation Accuracy: 64.36%Loss: 0.8833  Validation Accuracy: 65.22%Loss: 0.8542  Validation Accuracy: 66.96%Loss: 0.8779  Validation Accuracy: 67.20%Loss: 0.8726  Validation Accuracy: 66.46%Loss: 0.9025  Validation Accuracy: 64.48%Loss: 0.8819  Validation Accuracy: 64.98%Loss: 0.8541  Validation Accuracy: 67.95%Loss: 0.8760  Validation Accuracy: 67.08%Loss: 0.8708  Validation Accuracy: 66.34%Loss: 0.9012  Validation Accuracy: 64.11%Loss: 0.8812  Validation Accuracy: 65.10%Loss: 0.8510  Validation Accuracy: 66.96%Loss: 0.8762  Validation Accuracy: 67.08%Loss: 0.8693  Validation Accuracy: 66.46%Loss: 0.8985  Validation Accuracy: 64.73%Loss: 0.8785  Validation Accuracy: 64.85%Loss: 0.8501  Validation Accuracy: 67.45%Loss: 0.8743  Validation Accuracy: 67.57%Loss: 0.8696  Validation Accuracy: 66.09%Loss: 0.8991  Validation Accuracy: 64.11%Loss: 0.8790  Validation Accuracy: 65.47%Loss: 0.8486  Validation Accuracy: 66.46%Loss: 0.8733  Validation Accuracy: 66.21%Loss: 0.8672  Validation Accuracy: 66.83%Loss: 0.8951  Validation Accuracy: 64.98%Loss: 0.8736  Validation Accuracy: 65.59%Loss: 0.8464  Validation Accuracy: 67.08%Loss: 0.8706  Validation Accuracy: 67.45%Loss: 0.8671  Validation Accuracy: 65.97%Loss: 0.8946  Validation Accuracy: 64.48%Loss: 0.8736  Validation Accuracy: 65.72%Loss: 0.8480  Validation Accuracy: 67.70%Loss: 0.8688  Validation Accuracy: 67.95%Loss: 0.8645  Validation Accuracy: 66.71%Loss: 0.8931  Validation Accuracy: 64.36%Loss: 0.8745  Validation Accuracy: 65.47%Loss: 0.8441  Validation Accuracy: 66.71%Loss: 0.8652  Validation Accuracy: 68.07%Loss: 0.8631  Validation Accuracy: 66.96%Loss: 0.8908  Validation Accuracy: 64.85%Loss: 0.8707  Validation Accuracy: 66.34%Loss: 0.8451  Validation Accuracy: 66.96%Loss: 0.8645  Validation Accuracy: 68.07%Loss: 0.8617  Validation Accuracy: 67.08%Loss: 0.8903  Validation Accuracy: 64.48%Loss: 0.8710  Validation Accuracy: 65.59%Loss: 0.8428  Validation Accuracy: 67.45%Loss: 0.8630  Validation Accuracy: 68.07%Loss: 0.8631  Validation Accuracy: 66.71%Loss: 0.8907  Validation Accuracy: 63.74%Loss: 0.8707  Validation Accuracy: 65.84%Loss: 0.8387  Validation Accuracy: 67.08%Loss: 0.8622  Validation Accuracy: 67.33%Loss: 0.8617  Validation Accuracy: 67.70%Loss: 0.8860  Validation Accuracy: 65.22%Loss: 0.8677  Validation Accuracy: 65.72%Loss: 0.8414  Validation Accuracy: 67.70%Loss: 0.8611  Validation Accuracy: 67.95%Loss: 0.8585  Validation Accuracy: 67.20%Loss: 0.8862  Validation Accuracy: 64.85%Loss: 0.8657  Validation Accuracy: 66.09%Loss: 0.8450  Validation Accuracy: 67.20%Loss: 0.8621  Validation Accuracy: 67.33%Loss: 0.8583  Validation Accuracy: 67.33%Loss: 0.8831  Validation Accuracy: 64.73%Loss: 0.8649  Validation Accuracy: 65.35%Loss: 0.8444  Validation Accuracy: 66.96%Loss: 0.8615  Validation Accuracy: 67.82%Loss: 0.8570  Validation Accuracy: 66.96%Loss: 0.8801  Validation Accuracy: 65.22%Loss: 0.8589  Validation Accuracy: 66.34%Loss: 0.8385  Validation Accuracy: 67.08%Loss: 0.8612  Validation Accuracy: 68.07%Loss: 0.8601  Validation Accuracy: 67.08%Loss: 0.8808  Validation Accuracy: 65.47%Loss: 0.8603  Validation Accuracy: 66.21%Loss: 0.8417  Validation Accuracy: 67.33%Loss: 0.8616  Validation Accuracy: 67.70%Loss: 0.8607  Validation Accuracy: 66.58%Loss: 0.8835  Validation Accuracy: 64.11%Loss: 0.8581  Validation Accuracy: 65.97%Loss: 0.8378  Validation Accuracy: 67.08%Loss: 0.8596  Validation Accuracy: 67.70%Loss: 0.8598  Validation Accuracy: 67.20%Loss: 0.8864  Validation Accuracy: 64.48%Loss: 0.8556  Validation Accuracy: 67.08%Loss: 0.8349  Validation Accuracy: 67.08%Loss: 0.8576  Validation Accuracy: 68.32%Loss: 0.8556  Validation Accuracy: 67.57%Loss: 0.8884  Validation Accuracy: 64.73%Loss: 0.8587  Validation Accuracy: 66.21%Loss: 0.8301  Validation Accuracy: 67.20%Loss: 0.8488  Validation Accuracy: 68.69%Loss: 0.8522  Validation Accuracy: 66.96%Loss: 0.8829  Validation Accuracy: 64.60%Loss: 0.8559  Validation Accuracy: 66.58%Loss: 0.8284  Validation Accuracy: 66.96%Loss: 0.8499  Validation Accuracy: 68.44%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280, CIFAR-10 Batch 4:  Loss: 0.8528  Validation Accuracy: 67.45%Loss: 0.8811  Validation Accuracy: 65.22%Loss: 0.8603  Validation Accuracy: 65.84%Loss: 0.8285  Validation Accuracy: 66.83%Loss: 0.8480  Validation Accuracy: 68.19%Loss: 0.8504  Validation Accuracy: 68.32%Loss: 0.8732  Validation Accuracy: 64.73%Loss: 0.8531  Validation Accuracy: 66.46%Loss: 0.8296  Validation Accuracy: 66.71%Loss: 0.8462  Validation Accuracy: 68.56%Loss: 0.8494  Validation Accuracy: 68.32%Loss: 0.8715  Validation Accuracy: 65.59%Loss: 0.8477  Validation Accuracy: 66.96%Loss: 0.8235  Validation Accuracy: 67.08%Loss: 0.8431  Validation Accuracy: 68.81%Loss: 0.8458  Validation Accuracy: 67.08%Loss: 0.8719  Validation Accuracy: 65.59%Loss: 0.8484  Validation Accuracy: 66.34%Loss: 0.8224  Validation Accuracy: 67.20%Loss: 0.8416  Validation Accuracy: 68.19%Loss: 0.8503  Validation Accuracy: 67.95%Loss: 0.8732  Validation Accuracy: 65.84%Loss: 0.8510  Validation Accuracy: 66.46%Loss: 0.8222  Validation Accuracy: 67.33%Loss: 0.8423  Validation Accuracy: 68.94%Loss: 0.8471  Validation Accuracy: 68.07%Loss: 0.8715  Validation Accuracy: 65.97%Loss: 0.8457  Validation Accuracy: 66.09%Loss: 0.8203  Validation Accuracy: 66.96%Loss: 0.8422  Validation Accuracy: 68.56%Loss: 0.8441  Validation Accuracy: 67.70%Loss: 0.8670  Validation Accuracy: 66.34%Loss: 0.8459  Validation Accuracy: 66.58%Loss: 0.8172  Validation Accuracy: 66.83%Loss: 0.8379  Validation Accuracy: 68.81%Loss: 0.8468  Validation Accuracy: 67.82%Loss: 0.8676  Validation Accuracy: 66.34%Loss: 0.8487  Validation Accuracy: 66.71%Loss: 0.8142  Validation Accuracy: 66.96%Loss: 0.8354  Validation Accuracy: 68.69%Loss: 0.8436  Validation Accuracy: 68.32%Loss: 0.8661  Validation Accuracy: 66.83%Loss: 0.8473  Validation Accuracy: 66.96%Loss: 0.8142  Validation Accuracy: 67.45%Loss: 0.8337  Validation Accuracy: 69.06%Loss: 0.8387  Validation Accuracy: 67.20%Loss: 0.8624  Validation Accuracy: 67.08%Loss: 0.8425  Validation Accuracy: 67.08%Loss: 0.8123  Validation Accuracy: 67.33%Loss: 0.8321  Validation Accuracy: 68.19%Loss: 0.8365  Validation Accuracy: 67.82%Loss: 0.8610  Validation Accuracy: 66.83%Loss: 0.8433  Validation Accuracy: 67.95%Loss: 0.8121  Validation Accuracy: 67.70%Loss: 0.8305  Validation Accuracy: 68.07%Loss: 0.8370  Validation Accuracy: 67.45%Loss: 0.8593  Validation Accuracy: 66.71%Loss: 0.8430  Validation Accuracy: 66.83%Loss: 0.8119  Validation Accuracy: 67.20%Loss: 0.8299  Validation Accuracy: 67.95%Loss: 0.8349  Validation Accuracy: 67.57%Loss: 0.8579  Validation Accuracy: 66.83%Loss: 0.8402  Validation Accuracy: 67.20%Loss: 0.8096  Validation Accuracy: 67.70%Loss: 0.8280  Validation Accuracy: 68.44%Loss: 0.8322  Validation Accuracy: 67.57%Loss: 0.8562  Validation Accuracy: 66.58%Loss: 0.8410  Validation Accuracy: 67.57%Loss: 0.8090  Validation Accuracy: 67.33%Loss: 0.8289  Validation Accuracy: 67.82%Loss: 0.8311  Validation Accuracy: 67.45%Loss: 0.8530  Validation Accuracy: 67.20%Loss: 0.8336  Validation Accuracy: 67.33%Loss: 0.8064  Validation Accuracy: 67.33%Loss: 0.8270  Validation Accuracy: 67.70%Loss: 0.8285  Validation Accuracy: 67.70%Loss: 0.8515  Validation Accuracy: 66.46%Loss: 0.8347  Validation Accuracy: 67.20%Loss: 0.8054  Validation Accuracy: 67.70%Loss: 0.8256  Validation Accuracy: 68.07%Loss: 0.8275  Validation Accuracy: 67.70%Loss: 0.8502  Validation Accuracy: 66.09%Loss: 0.8306  Validation Accuracy: 67.57%Loss: 0.8025  Validation Accuracy: 67.45%Loss: 0.8220  Validation Accuracy: 68.19%Loss: 0.8265  Validation Accuracy: 67.45%Loss: 0.8472  Validation Accuracy: 66.21%Loss: 0.8275  Validation Accuracy: 67.95%Loss: 0.8016  Validation Accuracy: 68.19%Loss: 0.8226  Validation Accuracy: 68.19%Loss: 0.8251  Validation Accuracy: 68.44%Loss: 0.8453  Validation Accuracy: 66.46%Loss: 0.8286  Validation Accuracy: 67.08%Loss: 0.8017  Validation Accuracy: 67.70%Loss: 0.8197  Validation Accuracy: 68.32%Loss: 0.8243  Validation Accuracy: 67.95%Loss: 0.8454  Validation Accuracy: 66.46%Loss: 0.8247  Validation Accuracy: 67.57%Loss: 0.8024  Validation Accuracy: 67.45%Loss: 0.8185  Validation Accuracy: 67.95%Loss: 0.8230  Validation Accuracy: 67.95%Loss: 0.8408  Validation Accuracy: 67.20%Loss: 0.8252  Validation Accuracy: 66.58%Loss: 0.7979  Validation Accuracy: 68.32%Loss: 0.8185  Validation Accuracy: 68.69%Loss: 0.8211  Validation Accuracy: 68.07%Loss: 0.8386  Validation Accuracy: 67.08%Loss: 0.8203  Validation Accuracy: 67.08%Loss: 0.7958  Validation Accuracy: 68.32%Loss: 0.8170  Validation Accuracy: 68.94%Loss: 0.8240  Validation Accuracy: 68.07%Loss: 0.8404  Validation Accuracy: 66.58%Loss: 0.8166  Validation Accuracy: 68.19%Loss: 0.7950  Validation Accuracy: 67.57%Loss: 0.8115  Validation Accuracy: 68.69%Loss: 0.8189  Validation Accuracy: 68.69%Loss: 0.8360  Validation Accuracy: 67.33%Loss: 0.8152  Validation Accuracy: 68.07%Loss: 0.7923  Validation Accuracy: 67.57%Loss: 0.8118  Validation Accuracy: 68.69%Loss: 0.8191  Validation Accuracy: 68.44%Loss: 0.8338  Validation Accuracy: 67.33%Loss: 0.8150  Validation Accuracy: 68.19%Loss: 0.7919  Validation Accuracy: 68.32%Loss: 0.8100  Validation Accuracy: 69.80%Loss: 0.8175  Validation Accuracy: 68.44%Loss: 0.8315  Validation Accuracy: 67.57%Loss: 0.8110  Validation Accuracy: 68.32%Loss: 0.7904  Validation Accuracy: 67.45%Loss: 0.8069  Validation Accuracy: 69.06%Loss: 0.8173  Validation Accuracy: 68.56%Loss: 0.8340  Validation Accuracy: 66.83%Loss: 0.8111  Validation Accuracy: 68.32%Loss: 0.7896  Validation Accuracy: 68.32%Loss: 0.8061  Validation Accuracy: 68.44%Loss: 0.8147  Validation Accuracy: 68.81%Loss: 0.8264  Validation Accuracy: 67.57%Loss: 0.8100  Validation Accuracy: 68.69%Loss: 0.7893  Validation Accuracy: 68.19%Loss: 0.8066  Validation Accuracy: 69.06%Loss: 0.8137  Validation Accuracy: 68.19%Loss: 0.8277  Validation Accuracy: 67.95%Loss: 0.8088  Validation Accuracy: 68.07%Loss: 0.7891  Validation Accuracy: 68.19%Loss: 0.8031  Validation Accuracy: 69.06%Loss: 0.8126  Validation Accuracy: 68.32%Loss: 0.8247  Validation Accuracy: 68.19%Loss: 0.8077  Validation Accuracy: 68.32%Loss: 0.7912  Validation Accuracy: 69.18%Loss: 0.8033  Validation Accuracy: 69.31%Loss: 0.8127  Validation Accuracy: 68.94%Loss: 0.8273  Validation Accuracy: 67.33%Loss: 0.8067  Validation Accuracy: 68.19%Loss: 0.7879  Validation Accuracy: 68.56%Loss: 0.8006  Validation Accuracy: 69.55%Loss: 0.8104  Validation Accuracy: 68.56%Loss: 0.8231  Validation Accuracy: 68.44%Loss: 0.8045  Validation Accuracy: 67.82%Loss: 0.7857  Validation Accuracy: 68.19%Loss: 0.8018  Validation Accuracy: 69.31%Loss: 0.8086  Validation Accuracy: 68.69%Loss: 0.8215  Validation Accuracy: 67.95%Loss: 0.8024  Validation Accuracy: 69.06%Loss: 0.7869  Validation Accuracy: 68.81%Loss: 0.8017  Validation Accuracy: 69.43%Loss: 0.8085  Validation Accuracy: 68.69%Loss: 0.8217  Validation Accuracy: 67.95%Loss: 0.8011  Validation Accuracy: 68.56%Loss: 0.7843  Validation Accuracy: 69.06%Loss: 0.7992  Validation Accuracy: 70.17%Loss: 0.8069  Validation Accuracy: 68.94%Loss: 0.8209  Validation Accuracy: 67.70%Loss: 0.8012  Validation Accuracy: 68.69%Loss: 0.7879  Validation Accuracy: 68.81%Loss: 0.7971  Validation Accuracy: 70.67%Loss: 0.8068  Validation Accuracy: 68.56%Loss: 0.8180  Validation Accuracy: 68.56%Loss: 0.7976  Validation Accuracy: 68.69%Loss: 0.7834  Validation Accuracy: 69.06%Loss: 0.7959  Validation Accuracy: 70.42%Loss: 0.8087  Validation Accuracy: 68.81%Loss: 0.8191  Validation Accuracy: 67.57%Loss: 0.7961  Validation Accuracy: 68.44%Loss: 0.7856  Validation Accuracy: 68.81%Loss: 0.7965  Validation Accuracy: 70.05%Loss: 0.8069  Validation Accuracy: 69.06%Loss: 0.8174  Validation Accuracy: 68.19%Loss: 0.7967  Validation Accuracy: 68.32%Loss: 0.7851  Validation Accuracy: 68.81%Loss: 0.7944  Validation Accuracy: 70.42%Loss: 0.8059  Validation Accuracy: 68.94%Loss: 0.8172  Validation Accuracy: 67.70%Loss: 0.7966  Validation Accuracy: 68.56%Loss: 0.7826  Validation Accuracy: 68.69%Loss: 0.7972  Validation Accuracy: 70.30%Loss: 0.8069  Validation Accuracy: 68.81%Loss: 0.8160  Validation Accuracy: 68.44%Loss: 0.7955  Validation Accuracy: 68.44%Loss: 0.7788  Validation Accuracy: 69.06%Loss: 0.7922  Validation Accuracy: 70.79%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320, CIFAR-10 Batch 4:  Loss: 0.8061  Validation Accuracy: 69.68%Loss: 0.8175  Validation Accuracy: 68.32%Loss: 0.7903  Validation Accuracy: 69.06%Loss: 0.7771  Validation Accuracy: 68.56%Loss: 0.7890  Validation Accuracy: 71.41%Loss: 0.8043  Validation Accuracy: 69.31%Loss: 0.8141  Validation Accuracy: 67.82%Loss: 0.7897  Validation Accuracy: 68.81%Loss: 0.7734  Validation Accuracy: 68.69%Loss: 0.7859  Validation Accuracy: 70.67%Loss: 0.8002  Validation Accuracy: 69.06%Loss: 0.8117  Validation Accuracy: 68.56%Loss: 0.7911  Validation Accuracy: 68.94%Loss: 0.7720  Validation Accuracy: 68.69%Loss: 0.7847  Validation Accuracy: 70.67%Loss: 0.7999  Validation Accuracy: 69.93%Loss: 0.8096  Validation Accuracy: 68.44%Loss: 0.7887  Validation Accuracy: 69.43%Loss: 0.7691  Validation Accuracy: 69.06%Loss: 0.7799  Validation Accuracy: 70.54%Loss: 0.7973  Validation Accuracy: 69.31%Loss: 0.8107  Validation Accuracy: 68.81%Loss: 0.7893  Validation Accuracy: 69.68%Loss: 0.7667  Validation Accuracy: 68.94%Loss: 0.7772  Validation Accuracy: 70.67%Loss: 0.7969  Validation Accuracy: 69.18%Loss: 0.8088  Validation Accuracy: 68.94%Loss: 0.7891  Validation Accuracy: 69.55%Loss: 0.7671  Validation Accuracy: 68.44%Loss: 0.7766  Validation Accuracy: 70.54%Loss: 0.7946  Validation Accuracy: 69.43%Loss: 0.8042  Validation Accuracy: 68.69%Loss: 0.7837  Validation Accuracy: 69.93%Loss: 0.7642  Validation Accuracy: 68.44%Loss: 0.7749  Validation Accuracy: 70.79%Loss: 0.7923  Validation Accuracy: 68.81%Loss: 0.8044  Validation Accuracy: 69.18%Loss: 0.7828  Validation Accuracy: 69.80%Loss: 0.7632  Validation Accuracy: 68.44%Loss: 0.7727  Validation Accuracy: 71.04%Loss: 0.7914  Validation Accuracy: 69.43%Loss: 0.8014  Validation Accuracy: 69.06%Loss: 0.7807  Validation Accuracy: 70.17%Loss: 0.7612  Validation Accuracy: 69.18%Loss: 0.7727  Validation Accuracy: 70.92%Loss: 0.7908  Validation Accuracy: 69.43%Loss: 0.8006  Validation Accuracy: 70.05%Loss: 0.7771  Validation Accuracy: 70.30%Loss: 0.7598  Validation Accuracy: 68.81%Loss: 0.7697  Validation Accuracy: 71.53%Loss: 0.7880  Validation Accuracy: 68.56%Loss: 0.7973  Validation Accuracy: 69.68%Loss: 0.7786  Validation Accuracy: 69.80%Loss: 0.7581  Validation Accuracy: 69.31%Loss: 0.7671  Validation Accuracy: 71.16%Loss: 0.7894  Validation Accuracy: 68.69%Loss: 0.7964  Validation Accuracy: 69.80%Loss: 0.7724  Validation Accuracy: 69.93%Loss: 0.7577  Validation Accuracy: 69.18%Loss: 0.7661  Validation Accuracy: 71.16%Loss: 0.7832  Validation Accuracy: 70.05%Loss: 0.7959  Validation Accuracy: 70.42%Loss: 0.7719  Validation Accuracy: 70.42%Loss: 0.7555  Validation Accuracy: 69.06%Loss: 0.7653  Validation Accuracy: 71.16%Loss: 0.7815  Validation Accuracy: 69.31%Loss: 0.7943  Validation Accuracy: 69.93%Loss: 0.7712  Validation Accuracy: 70.30%Loss: 0.7532  Validation Accuracy: 69.06%Loss: 0.7634  Validation Accuracy: 71.04%Loss: 0.7805  Validation Accuracy: 69.18%Loss: 0.7932  Validation Accuracy: 70.05%Loss: 0.7687  Validation Accuracy: 70.54%Loss: 0.7529  Validation Accuracy: 69.31%Loss: 0.7629  Validation Accuracy: 71.53%Loss: 0.7757  Validation Accuracy: 69.31%Loss: 0.7913  Validation Accuracy: 70.30%Loss: 0.7662  Validation Accuracy: 70.79%Loss: 0.7529  Validation Accuracy: 69.31%Loss: 0.7619  Validation Accuracy: 71.66%Loss: 0.7748  Validation Accuracy: 68.94%Loss: 0.7893  Validation Accuracy: 70.54%Loss: 0.7636  Validation Accuracy: 70.79%Loss: 0.7527  Validation Accuracy: 69.93%Loss: 0.7604  Validation Accuracy: 72.03%Loss: 0.7724  Validation Accuracy: 70.05%Loss: 0.7885  Validation Accuracy: 70.30%Loss: 0.7652  Validation Accuracy: 70.30%Loss: 0.7507  Validation Accuracy: 69.68%Loss: 0.7587  Validation Accuracy: 72.03%Loss: 0.7720  Validation Accuracy: 69.43%Loss: 0.7860  Validation Accuracy: 70.42%Loss: 0.7612  Validation Accuracy: 70.17%Loss: 0.7496  Validation Accuracy: 70.05%Loss: 0.7574  Validation Accuracy: 71.66%Loss: 0.7683  Validation Accuracy: 70.30%Loss: 0.7850  Validation Accuracy: 70.79%Loss: 0.7586  Validation Accuracy: 70.17%Loss: 0.7455  Validation Accuracy: 70.05%Loss: 0.7553  Validation Accuracy: 71.91%Loss: 0.7665  Validation Accuracy: 69.80%Loss: 0.7854  Validation Accuracy: 70.92%Loss: 0.7575  Validation Accuracy: 70.67%Loss: 0.7445  Validation Accuracy: 68.94%Loss: 0.7553  Validation Accuracy: 72.28%Loss: 0.7671  Validation Accuracy: 70.54%Loss: 0.7827  Validation Accuracy: 71.16%Loss: 0.7574  Validation Accuracy: 70.42%Loss: 0.7438  Validation Accuracy: 69.80%Loss: 0.7561  Validation Accuracy: 71.78%Loss: 0.7661  Validation Accuracy: 69.55%Loss: 0.7817  Validation Accuracy: 71.04%Loss: 0.7555  Validation Accuracy: 70.79%Loss: 0.7437  Validation Accuracy: 70.17%Loss: 0.7517  Validation Accuracy: 72.40%Loss: 0.7644  Validation Accuracy: 69.68%Loss: 0.7791  Validation Accuracy: 71.04%Loss: 0.7529  Validation Accuracy: 71.16%Loss: 0.7421  Validation Accuracy: 70.42%Loss: 0.7524  Validation Accuracy: 72.03%Loss: 0.7610  Validation Accuracy: 69.68%Loss: 0.7803  Validation Accuracy: 70.92%Loss: 0.7523  Validation Accuracy: 70.92%Loss: 0.7371  Validation Accuracy: 69.68%Loss: 0.7486  Validation Accuracy: 72.03%Loss: 0.7606  Validation Accuracy: 70.67%Loss: 0.7784  Validation Accuracy: 71.04%Loss: 0.7500  Validation Accuracy: 70.92%Loss: 0.7381  Validation Accuracy: 69.80%Loss: 0.7483  Validation Accuracy: 72.65%Loss: 0.7604  Validation Accuracy: 69.80%Loss: 0.7754  Validation Accuracy: 70.67%Loss: 0.7477  Validation Accuracy: 71.41%Loss: 0.7371  Validation Accuracy: 70.92%Loss: 0.7470  Validation Accuracy: 72.90%Loss: 0.7583  Validation Accuracy: 70.67%Loss: 0.7743  Validation Accuracy: 71.41%Loss: 0.7473  Validation Accuracy: 71.78%Loss: 0.7341  Validation Accuracy: 70.30%Loss: 0.7461  Validation Accuracy: 72.90%Loss: 0.7574  Validation Accuracy: 70.42%Loss: 0.7751  Validation Accuracy: 71.53%Loss: 0.7473  Validation Accuracy: 71.29%Loss: 0.7360  Validation Accuracy: 70.67%Loss: 0.7467  Validation Accuracy: 72.15%Loss: 0.7562  Validation Accuracy: 70.79%Loss: 0.7717  Validation Accuracy: 71.41%Loss: 0.7439  Validation Accuracy: 71.04%Loss: 0.7353  Validation Accuracy: 70.79%Loss: 0.7439  Validation Accuracy: 72.40%Loss: 0.7535  Validation Accuracy: 71.41%Loss: 0.7710  Validation Accuracy: 71.78%Loss: 0.7439  Validation Accuracy: 71.29%Loss: 0.7304  Validation Accuracy: 69.80%Loss: 0.7425  Validation Accuracy: 72.03%Loss: 0.7534  Validation Accuracy: 70.54%Loss: 0.7703  Validation Accuracy: 71.29%Loss: 0.7412  Validation Accuracy: 71.91%Loss: 0.7286  Validation Accuracy: 70.05%Loss: 0.7412  Validation Accuracy: 72.40%Loss: 0.7531  Validation Accuracy: 70.92%Loss: 0.7679  Validation Accuracy: 72.03%Loss: 0.7423  Validation Accuracy: 71.04%Loss: 0.7297  Validation Accuracy: 70.67%Loss: 0.7402  Validation Accuracy: 73.02%Loss: 0.7518  Validation Accuracy: 71.29%Loss: 0.7675  Validation Accuracy: 71.53%Loss: 0.7413  Validation Accuracy: 71.53%Loss: 0.7262  Validation Accuracy: 70.42%Loss: 0.7395  Validation Accuracy: 72.77%Loss: 0.7484  Validation Accuracy: 71.41%Loss: 0.7669  Validation Accuracy: 71.66%Loss: 0.7400  Validation Accuracy: 71.16%Loss: 0.7252  Validation Accuracy: 70.42%Loss: 0.7379  Validation Accuracy: 72.15%Loss: 0.7482  Validation Accuracy: 70.54%Loss: 0.7672  Validation Accuracy: 71.53%Loss: 0.7395  Validation Accuracy: 71.29%Loss: 0.7218  Validation Accuracy: 69.93%Loss: 0.7351  Validation Accuracy: 73.02%Loss: 0.7490  Validation Accuracy: 70.67%Loss: 0.7650  Validation Accuracy: 71.53%Loss: 0.7357  Validation Accuracy: 71.53%Loss: 0.7216  Validation Accuracy: 70.17%Loss: 0.7357  Validation Accuracy: 73.02%Loss: 0.7462  Validation Accuracy: 71.66%Loss: 0.7642  Validation Accuracy: 71.78%Loss: 0.7360  Validation Accuracy: 71.91%Loss: 0.7217  Validation Accuracy: 70.92%Loss: 0.7370  Validation Accuracy: 73.14%Loss: 0.7460  Validation Accuracy: 70.79%Loss: 0.7624  Validation Accuracy: 72.15%Loss: 0.7325  Validation Accuracy: 71.16%Loss: 0.7193  Validation Accuracy: 70.92%Loss: 0.7321  Validation Accuracy: 72.77%Loss: 0.7440  Validation Accuracy: 71.04%Loss: 0.7620  Validation Accuracy: 72.03%Loss: 0.7320  Validation Accuracy: 71.53%Loss: 0.7211  Validation Accuracy: 71.78%Loss: 0.7337  Validation Accuracy: 73.02%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360, CIFAR-10 Batch 4:  Loss: 0.7432  Validation Accuracy: 72.03%Loss: 0.7602  Validation Accuracy: 71.29%Loss: 0.7306  Validation Accuracy: 71.66%Loss: 0.7163  Validation Accuracy: 70.67%Loss: 0.7305  Validation Accuracy: 73.02%Loss: 0.7419  Validation Accuracy: 71.91%Loss: 0.7590  Validation Accuracy: 71.41%Loss: 0.7288  Validation Accuracy: 71.91%Loss: 0.7167  Validation Accuracy: 70.79%Loss: 0.7307  Validation Accuracy: 73.14%Loss: 0.7392  Validation Accuracy: 70.92%Loss: 0.7571  Validation Accuracy: 71.66%Loss: 0.7267  Validation Accuracy: 70.79%Loss: 0.7140  Validation Accuracy: 70.92%Loss: 0.7304  Validation Accuracy: 72.77%Loss: 0.7388  Validation Accuracy: 71.78%Loss: 0.7583  Validation Accuracy: 72.03%Loss: 0.7261  Validation Accuracy: 71.78%Loss: 0.7165  Validation Accuracy: 71.04%Loss: 0.7289  Validation Accuracy: 73.51%Loss: 0.7351  Validation Accuracy: 71.78%Loss: 0.7539  Validation Accuracy: 72.40%Loss: 0.7254  Validation Accuracy: 72.28%Loss: 0.7115  Validation Accuracy: 71.04%Loss: 0.7258  Validation Accuracy: 73.39%Loss: 0.7356  Validation Accuracy: 72.40%Loss: 0.7546  Validation Accuracy: 72.15%Loss: 0.7242  Validation Accuracy: 72.40%Loss: 0.7105  Validation Accuracy: 71.53%Loss: 0.7254  Validation Accuracy: 73.39%Loss: 0.7357  Validation Accuracy: 71.04%Loss: 0.7537  Validation Accuracy: 72.40%Loss: 0.7230  Validation Accuracy: 72.15%Loss: 0.7083  Validation Accuracy: 71.29%Loss: 0.7225  Validation Accuracy: 72.90%Loss: 0.7336  Validation Accuracy: 72.15%Loss: 0.7525  Validation Accuracy: 72.52%Loss: 0.7228  Validation Accuracy: 72.03%Loss: 0.7106  Validation Accuracy: 71.29%Loss: 0.7229  Validation Accuracy: 73.64%Loss: 0.7312  Validation Accuracy: 72.15%Loss: 0.7494  Validation Accuracy: 72.65%Loss: 0.7221  Validation Accuracy: 72.03%Loss: 0.7075  Validation Accuracy: 71.29%Loss: 0.7205  Validation Accuracy: 73.51%Loss: 0.7317  Validation Accuracy: 72.40%Loss: 0.7512  Validation Accuracy: 72.15%Loss: 0.7202  Validation Accuracy: 72.40%Loss: 0.7046  Validation Accuracy: 71.41%Loss: 0.7191  Validation Accuracy: 73.27%Loss: 0.7294  Validation Accuracy: 73.02%Loss: 0.7482  Validation Accuracy: 72.52%Loss: 0.7189  Validation Accuracy: 72.52%Loss: 0.7031  Validation Accuracy: 71.53%Loss: 0.7157  Validation Accuracy: 73.76%Loss: 0.7306  Validation Accuracy: 71.91%Loss: 0.7449  Validation Accuracy: 72.65%Loss: 0.7198  Validation Accuracy: 72.65%Loss: 0.7036  Validation Accuracy: 70.67%Loss: 0.7172  Validation Accuracy: 73.64%Loss: 0.7273  Validation Accuracy: 72.65%Loss: 0.7448  Validation Accuracy: 72.65%Loss: 0.7152  Validation Accuracy: 71.91%Loss: 0.7044  Validation Accuracy: 71.16%Loss: 0.7173  Validation Accuracy: 73.76%Loss: 0.7271  Validation Accuracy: 72.03%Loss: 0.7450  Validation Accuracy: 73.14%Loss: 0.7189  Validation Accuracy: 72.77%Loss: 0.7006  Validation Accuracy: 70.67%Loss: 0.7138  Validation Accuracy: 73.51%Loss: 0.7252  Validation Accuracy: 71.78%Loss: 0.7433  Validation Accuracy: 73.27%Loss: 0.7159  Validation Accuracy: 72.77%Loss: 0.7015  Validation Accuracy: 71.91%Loss: 0.7161  Validation Accuracy: 73.89%Loss: 0.7240  Validation Accuracy: 72.15%Loss: 0.7419  Validation Accuracy: 73.02%Loss: 0.7146  Validation Accuracy: 72.28%Loss: 0.6981  Validation Accuracy: 71.29%Loss: 0.7125  Validation Accuracy: 74.01%Loss: 0.7214  Validation Accuracy: 73.14%Loss: 0.7397  Validation Accuracy: 73.27%Loss: 0.7129  Validation Accuracy: 72.90%Loss: 0.6972  Validation Accuracy: 71.66%Loss: 0.7109  Validation Accuracy: 74.01%Loss: 0.7228  Validation Accuracy: 73.27%Loss: 0.7388  Validation Accuracy: 73.27%Loss: 0.7108  Validation Accuracy: 72.65%Loss: 0.6962  Validation Accuracy: 71.29%Loss: 0.7097  Validation Accuracy: 74.13%Loss: 0.7196  Validation Accuracy: 72.65%Loss: 0.7406  Validation Accuracy: 73.39%Loss: 0.7150  Validation Accuracy: 73.27%Loss: 0.6972  Validation Accuracy: 71.29%Loss: 0.7087  Validation Accuracy: 74.26%Loss: 0.7201  Validation Accuracy: 72.28%Loss: 0.7368  Validation Accuracy: 73.14%Loss: 0.7087  Validation Accuracy: 72.40%Loss: 0.6944  Validation Accuracy: 72.15%Loss: 0.7090  Validation Accuracy: 74.26%Loss: 0.7172  Validation Accuracy: 73.02%Loss: 0.7374  Validation Accuracy: 72.90%Loss: 0.7078  Validation Accuracy: 73.51%Loss: 0.6943  Validation Accuracy: 72.03%Loss: 0.7069  Validation Accuracy: 74.26%Loss: 0.7163  Validation Accuracy: 72.77%Loss: 0.7340  Validation Accuracy: 73.27%Loss: 0.7093  Validation Accuracy: 73.51%Loss: 0.6942  Validation Accuracy: 72.03%Loss: 0.7074  Validation Accuracy: 74.50%Loss: 0.7171  Validation Accuracy: 73.51%Loss: 0.7345  Validation Accuracy: 73.39%Loss: 0.7072  Validation Accuracy: 73.89%Loss: 0.6908  Validation Accuracy: 72.03%Loss: 0.7057  Validation Accuracy: 74.75%Loss: 0.7142  Validation Accuracy: 73.14%Loss: 0.7356  Validation Accuracy: 73.27%Loss: 0.7084  Validation Accuracy: 73.76%Loss: 0.6900  Validation Accuracy: 72.52%Loss: 0.7054  Validation Accuracy: 74.63%Loss: 0.7156  Validation Accuracy: 72.65%Loss: 0.7331  Validation Accuracy: 73.39%Loss: 0.7056  Validation Accuracy: 73.27%Loss: 0.6877  Validation Accuracy: 72.28%Loss: 0.7046  Validation Accuracy: 74.88%Loss: 0.7136  Validation Accuracy: 72.77%Loss: 0.7319  Validation Accuracy: 73.14%Loss: 0.7038  Validation Accuracy: 73.51%Loss: 0.6861  Validation Accuracy: 72.65%Loss: 0.7013  Validation Accuracy: 74.88%Loss: 0.7114  Validation Accuracy: 73.64%Loss: 0.7286  Validation Accuracy: 73.64%Loss: 0.7065  Validation Accuracy: 73.27%Loss: 0.6867  Validation Accuracy: 72.90%Loss: 0.7010  Validation Accuracy: 74.38%Loss: 0.7116  Validation Accuracy: 73.39%Loss: 0.7295  Validation Accuracy: 73.76%Loss: 0.7017  Validation Accuracy: 74.01%Loss: 0.6834  Validation Accuracy: 72.77%Loss: 0.6991  Validation Accuracy: 74.88%Loss: 0.7094  Validation Accuracy: 73.51%Loss: 0.7273  Validation Accuracy: 74.01%Loss: 0.7027  Validation Accuracy: 73.51%Loss: 0.6840  Validation Accuracy: 72.65%Loss: 0.6992  Validation Accuracy: 75.00%Loss: 0.7092  Validation Accuracy: 73.14%Loss: 0.7270  Validation Accuracy: 74.01%Loss: 0.7059  Validation Accuracy: 73.64%Loss: 0.6834  Validation Accuracy: 72.65%Loss: 0.6979  Validation Accuracy: 75.25%Loss: 0.7069  Validation Accuracy: 73.39%Loss: 0.7249  Validation Accuracy: 74.01%Loss: 0.6999  Validation Accuracy: 73.76%Loss: 0.6827  Validation Accuracy: 73.14%Loss: 0.6995  Validation Accuracy: 74.50%Loss: 0.7062  Validation Accuracy: 73.39%Loss: 0.7241  Validation Accuracy: 74.38%Loss: 0.6991  Validation Accuracy: 73.39%Loss: 0.6808  Validation Accuracy: 72.65%Loss: 0.6961  Validation Accuracy: 75.37%Loss: 0.7063  Validation Accuracy: 73.64%Loss: 0.7254  Validation Accuracy: 74.01%Loss: 0.7006  Validation Accuracy: 74.13%Loss: 0.6799  Validation Accuracy: 73.14%Loss: 0.6952  Validation Accuracy: 75.37%Loss: 0.7036  Validation Accuracy: 73.64%Loss: 0.7214  Validation Accuracy: 74.26%Loss: 0.6980  Validation Accuracy: 73.89%Loss: 0.6780  Validation Accuracy: 73.27%Loss: 0.6956  Validation Accuracy: 75.00%Loss: 0.7012  Validation Accuracy: 73.64%Loss: 0.7178  Validation Accuracy: 74.26%Loss: 0.6997  Validation Accuracy: 73.64%Loss: 0.6794  Validation Accuracy: 73.14%Loss: 0.6960  Validation Accuracy: 74.63%Loss: 0.7035  Validation Accuracy: 73.89%Loss: 0.7210  Validation Accuracy: 74.13%Loss: 0.6957  Validation Accuracy: 74.50%Loss: 0.6750  Validation Accuracy: 73.89%Loss: 0.6928  Validation Accuracy: 75.25%Loss: 0.7007  Validation Accuracy: 73.39%Loss: 0.7181  Validation Accuracy: 74.01%Loss: 0.6968  Validation Accuracy: 74.38%Loss: 0.6747  Validation Accuracy: 73.51%Loss: 0.6924  Validation Accuracy: 74.75%Loss: 0.7018  Validation Accuracy: 74.38%Loss: 0.7175  Validation Accuracy: 74.50%Loss: 0.6965  Validation Accuracy: 74.38%Loss: 0.6758  Validation Accuracy: 73.64%Loss: 0.6916  Validation Accuracy: 75.00%Loss: 0.6971  Validation Accuracy: 74.50%Loss: 0.7149  Validation Accuracy: 74.26%Loss: 0.6981  Validation Accuracy: 74.50%Loss: 0.6751  Validation Accuracy: 74.01%Loss: 0.6931  Validation Accuracy: 74.88%Loss: 0.6972  Validation Accuracy: 74.38%Loss: 0.7135  Validation Accuracy: 74.38%Loss: 0.6944  Validation Accuracy: 73.76%Loss: 0.6726  Validation Accuracy: 73.27%Loss: 0.6884  Validation Accuracy: 75.00%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, CIFAR-10 Batch 4:  Loss: 0.6966  Validation Accuracy: 74.26%Loss: 0.7152  Validation Accuracy: 74.75%Loss: 0.6945  Validation Accuracy: 74.26%Loss: 0.6719  Validation Accuracy: 74.13%Loss: 0.6898  Validation Accuracy: 75.00%Loss: 0.6968  Validation Accuracy: 74.01%Loss: 0.7124  Validation Accuracy: 74.50%Loss: 0.6959  Validation Accuracy: 74.01%Loss: 0.6722  Validation Accuracy: 74.01%Loss: 0.6878  Validation Accuracy: 75.12%Loss: 0.6938  Validation Accuracy: 74.26%Loss: 0.7121  Validation Accuracy: 73.76%Loss: 0.6907  Validation Accuracy: 75.37%Loss: 0.6698  Validation Accuracy: 74.13%Loss: 0.6879  Validation Accuracy: 75.37%Loss: 0.6953  Validation Accuracy: 73.89%Loss: 0.7110  Validation Accuracy: 74.75%Loss: 0.6923  Validation Accuracy: 74.88%Loss: 0.6712  Validation Accuracy: 73.64%Loss: 0.6866  Validation Accuracy: 74.88%Loss: 0.6957  Validation Accuracy: 74.75%Loss: 0.7087  Validation Accuracy: 74.75%Loss: 0.6890  Validation Accuracy: 74.75%Loss: 0.6708  Validation Accuracy: 74.01%Loss: 0.6846  Validation Accuracy: 75.62%Loss: 0.6921  Validation Accuracy: 74.26%Loss: 0.7090  Validation Accuracy: 75.00%Loss: 0.6916  Validation Accuracy: 74.38%Loss: 0.6672  Validation Accuracy: 74.26%Loss: 0.6874  Validation Accuracy: 75.12%Loss: 0.6931  Validation Accuracy: 74.13%Loss: 0.7062  Validation Accuracy: 75.37%Loss: 0.6902  Validation Accuracy: 74.38%Loss: 0.6691  Validation Accuracy: 73.51%Loss: 0.6835  Validation Accuracy: 75.25%Loss: 0.6904  Validation Accuracy: 74.88%Loss: 0.7074  Validation Accuracy: 74.63%Loss: 0.6891  Validation Accuracy: 74.38%Loss: 0.6665  Validation Accuracy: 73.51%Loss: 0.6842  Validation Accuracy: 75.62%Loss: 0.6901  Validation Accuracy: 75.12%Loss: 0.7089  Validation Accuracy: 74.13%Loss: 0.6863  Validation Accuracy: 74.38%Loss: 0.6658  Validation Accuracy: 74.50%Loss: 0.6820  Validation Accuracy: 75.50%Loss: 0.6916  Validation Accuracy: 75.00%Loss: 0.7084  Validation Accuracy: 75.25%Loss: 0.6858  Validation Accuracy: 74.26%Loss: 0.6655  Validation Accuracy: 73.76%Loss: 0.6801  Validation Accuracy: 75.37%Loss: 0.6892  Validation Accuracy: 74.38%Loss: 0.7110  Validation Accuracy: 74.75%Loss: 0.6930  Validation Accuracy: 72.40%Loss: 0.6634  Validation Accuracy: 73.51%Loss: 0.6753  Validation Accuracy: 75.87%Loss: 0.6892  Validation Accuracy: 74.26%Loss: 0.7080  Validation Accuracy: 74.26%Loss: 0.6900  Validation Accuracy: 73.02%Loss: 0.6681  Validation Accuracy: 73.27%Loss: 0.6770  Validation Accuracy: 75.37%Loss: 0.6866  Validation Accuracy: 74.26%Loss: 0.7028  Validation Accuracy: 75.00%Loss: 0.6942  Validation Accuracy: 72.77%Loss: 0.6722  Validation Accuracy: 73.76%Loss: 0.6753  Validation Accuracy: 75.25%Loss: 0.6860  Validation Accuracy: 74.50%Loss: 0.7025  Validation Accuracy: 75.00%Loss: 0.6854  Validation Accuracy: 73.27%Loss: 0.6630  Validation Accuracy: 73.64%Loss: 0.6748  Validation Accuracy: 75.37%Loss: 0.6877  Validation Accuracy: 74.01%Loss: 0.6987  Validation Accuracy: 75.62%Loss: 0.6824  Validation Accuracy: 74.38%Loss: 0.6695  Validation Accuracy: 74.13%Loss: 0.6876  Validation Accuracy: 75.12%Loss: 0.6887  Validation Accuracy: 74.75%Loss: 0.6995  Validation Accuracy: 75.37%Loss: 0.6814  Validation Accuracy: 74.26%Loss: 0.6661  Validation Accuracy: 74.38%Loss: 0.6870  Validation Accuracy: 75.25%Loss: 0.7008  Validation Accuracy: 73.76%Loss: 0.7086  Validation Accuracy: 74.88%Loss: 0.6772  Validation Accuracy: 74.63%Loss: 0.6630  Validation Accuracy: 74.13%Loss: 0.6854  Validation Accuracy: 75.25%Loss: 0.7025  Validation Accuracy: 73.76%Loss: 0.7249  Validation Accuracy: 74.01%Loss: 0.6798  Validation Accuracy: 73.76%Loss: 0.6612  Validation Accuracy: 75.12%Loss: 0.6745  Validation Accuracy: 75.99%Loss: 0.6974  Validation Accuracy: 74.38%Loss: 0.7395  Validation Accuracy: 73.27%Loss: 0.6925  Validation Accuracy: 72.65%Loss: 0.6763  Validation Accuracy: 74.38%Loss: 0.6718  Validation Accuracy: 75.37%Loss: 0.6819  Validation Accuracy: 74.75%Loss: 0.7130  Validation Accuracy: 74.63%Loss: 0.6940  Validation Accuracy: 72.28%Loss: 0.6950  Validation Accuracy: 73.89%Loss: 0.6843  Validation Accuracy: 75.37%Loss: 0.6846  Validation Accuracy: 74.38%Loss: 0.6951  Validation Accuracy: 75.00%Loss: 0.6804  Validation Accuracy: 72.40%Loss: 0.6773  Validation Accuracy: 74.63%Loss: 0.6741  Validation Accuracy: 75.37%Loss: 0.6793  Validation Accuracy: 75.25%Loss: 0.6931  Validation Accuracy: 75.25%Loss: 0.6732  Validation Accuracy: 73.39%Loss: 0.6604  Validation Accuracy: 74.50%Loss: 0.6671  Validation Accuracy: 76.24%Loss: 0.6772  Validation Accuracy: 75.50%Loss: 0.6930  Validation Accuracy: 75.74%Loss: 0.6712  Validation Accuracy: 74.50%Loss: 0.6578  Validation Accuracy: 75.00%Loss: 0.6636  Validation Accuracy: 76.24%Loss: 0.6745  Validation Accuracy: 76.11%Loss: 0.6932  Validation Accuracy: 76.11%Loss: 0.6702  Validation Accuracy: 74.13%Loss: 0.6598  Validation Accuracy: 75.25%Loss: 0.6642  Validation Accuracy: 76.73%Loss: 0.6744  Validation Accuracy: 75.25%Loss: 0.6907  Validation Accuracy: 75.74%Loss: 0.6703  Validation Accuracy: 74.01%Loss: 0.6589  Validation Accuracy: 75.00%Loss: 0.6640  Validation Accuracy: 76.36%Loss: 0.6735  Validation Accuracy: 75.37%Loss: 0.6870  Validation Accuracy: 75.99%Loss: 0.6684  Validation Accuracy: 74.38%Loss: 0.6577  Validation Accuracy: 75.37%Loss: 0.6634  Validation Accuracy: 76.73%Loss: 0.6715  Validation Accuracy: 75.12%Loss: 0.6862  Validation Accuracy: 76.11%Loss: 0.6682  Validation Accuracy: 74.75%Loss: 0.6552  Validation Accuracy: 75.12%Loss: 0.6598  Validation Accuracy: 76.36%Loss: 0.6705  Validation Accuracy: 75.12%Loss: 0.6860  Validation Accuracy: 75.50%Loss: 0.6664  Validation Accuracy: 75.12%Loss: 0.6539  Validation Accuracy: 75.74%Loss: 0.6586  Validation Accuracy: 76.36%Loss: 0.6692  Validation Accuracy: 75.74%Loss: 0.6864  Validation Accuracy: 75.12%Loss: 0.6650  Validation Accuracy: 75.62%Loss: 0.6518  Validation Accuracy: 75.87%Loss: 0.6586  Validation Accuracy: 76.61%Loss: 0.6679  Validation Accuracy: 75.12%Loss: 0.6839  Validation Accuracy: 76.61%Loss: 0.6655  Validation Accuracy: 74.75%Loss: 0.6547  Validation Accuracy: 75.37%Loss: 0.6597  Validation Accuracy: 76.61%Loss: 0.6679  Validation Accuracy: 75.00%Loss: 0.6811  Validation Accuracy: 76.11%Loss: 0.6656  Validation Accuracy: 74.63%Loss: 0.6557  Validation Accuracy: 75.62%Loss: 0.6588  Validation Accuracy: 76.36%Loss: 0.6700  Validation Accuracy: 75.37%Loss: 0.6795  Validation Accuracy: 75.74%Loss: 0.6642  Validation Accuracy: 75.00%Loss: 0.6488  Validation Accuracy: 75.74%Loss: 0.6579  Validation Accuracy: 76.49%Loss: 0.6677  Validation Accuracy: 74.63%Loss: 0.6788  Validation Accuracy: 76.24%Loss: 0.6642  Validation Accuracy: 73.89%Loss: 0.6462  Validation Accuracy: 75.87%Loss: 0.6543  Validation Accuracy: 76.49%Loss: 0.6639  Validation Accuracy: 75.74%Loss: 0.6770  Validation Accuracy: 76.24%Loss: 0.6615  Validation Accuracy: 74.75%Loss: 0.6458  Validation Accuracy: 75.87%Loss: 0.6523  Validation Accuracy: 76.61%Loss: 0.6656  Validation Accuracy: 75.87%Loss: 0.6756  Validation Accuracy: 76.61%Loss: 0.6621  Validation Accuracy: 75.74%Loss: 0.6425  Validation Accuracy: 75.99%Loss: 0.6528  Validation Accuracy: 76.61%Loss: 0.6631  Validation Accuracy: 76.49%Loss: 0.6751  Validation Accuracy: 76.36%Loss: 0.6610  Validation Accuracy: 74.75%Loss: 0.6427  Validation Accuracy: 75.87%Loss: 0.6513  Validation Accuracy: 77.10%Loss: 0.6616  Validation Accuracy: 75.74%Loss: 0.6786  Validation Accuracy: 76.49%Loss: 0.6630  Validation Accuracy: 75.00%Loss: 0.6448  Validation Accuracy: 76.24%Loss: 0.6503  Validation Accuracy: 76.98%Loss: 0.6638  Validation Accuracy: 76.11%Loss: 0.6747  Validation Accuracy: 76.86%Loss: 0.6588  Validation Accuracy: 75.50%Loss: 0.6405  Validation Accuracy: 76.49%Loss: 0.6497  Validation Accuracy: 77.10%Loss: 0.6599  Validation Accuracy: 76.11%Loss: 0.6777  Validation Accuracy: 76.36%Loss: 0.6604  Validation Accuracy: 74.88%Loss: 0.6426  Validation Accuracy: 76.24%Loss: 0.6490  Validation Accuracy: 76.86%Loss: 0.6586  Validation Accuracy: 76.61%Loss: 0.6732  Validation Accuracy: 75.74%Loss: 0.6594  Validation Accuracy: 75.25%Loss: 0.6446  Validation Accuracy: 76.11%Loss: 0.6487  Validation Accuracy: 77.23%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, CIFAR-10 Batch 5:  Loss: 0.6587  Validation Accuracy: 76.24%\r"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5501451849937439\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERGJNDkWEREREYn+P68ec9U57p6FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f46887c10f0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:image-classification]",
   "language": "python",
   "name": "conda-env-image-classification-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
